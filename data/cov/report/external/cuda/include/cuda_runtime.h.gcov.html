<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - stripped_conv.info - external/cuda/include/cuda_runtime.h</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">external/cuda/include</a> - cuda_runtime.h<span style="font-size: 80%;"> (source / <a href="cuda_runtime.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">stripped_conv.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">2</td>
            <td class="headerCovTableEntry">2</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2020-05-21 16:34:32</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td></td>
            <td></td>
            <td></td>
            <td class="headerItem">Branches:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntryHi">-</td>
          </tr>
          <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">           Branch data     Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>                :            : /*</a>
<span class="lineNum">       2 </span>                :            :  * Copyright 1993-2018 NVIDIA Corporation.  All rights reserved.
<span class="lineNum">       3 </span>                :            :  *
<span class="lineNum">       4 </span>                :            :  * NOTICE TO LICENSEE:
<span class="lineNum">       5 </span>                :            :  *
<span class="lineNum">       6 </span>                :            :  * This source code and/or documentation (&quot;Licensed Deliverables&quot;) are
<span class="lineNum">       7 </span>                :            :  * subject to NVIDIA intellectual property rights under U.S. and
<span class="lineNum">       8 </span>                :            :  * international Copyright laws.
<span class="lineNum">       9 </span>                :            :  *
<span class="lineNum">      10 </span>                :            :  * These Licensed Deliverables contained herein is PROPRIETARY and
<span class="lineNum">      11 </span>                :            :  * CONFIDENTIAL to NVIDIA and is being provided under the terms and
<span class="lineNum">      12 </span>                :            :  * conditions of a form of NVIDIA software license agreement by and
<span class="lineNum">      13 </span>                :            :  * between NVIDIA and Licensee (&quot;License Agreement&quot;) or electronically
<span class="lineNum">      14 </span>                :            :  * accepted by Licensee.  Notwithstanding any terms or conditions to
<span class="lineNum">      15 </span>                :            :  * the contrary in the License Agreement, reproduction or disclosure
<span class="lineNum">      16 </span>                :            :  * of the Licensed Deliverables to any third party without the express
<span class="lineNum">      17 </span>                :            :  * written consent of NVIDIA is prohibited.
<span class="lineNum">      18 </span>                :            :  *
<span class="lineNum">      19 </span>                :            :  * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
<span class="lineNum">      20 </span>                :            :  * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
<span class="lineNum">      21 </span>                :            :  * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
<span class="lineNum">      22 </span>                :            :  * PROVIDED &quot;AS IS&quot; WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
<span class="lineNum">      23 </span>                :            :  * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
<span class="lineNum">      24 </span>                :            :  * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
<span class="lineNum">      25 </span>                :            :  * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
<span class="lineNum">      26 </span>                :            :  * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
<span class="lineNum">      27 </span>                :            :  * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
<span class="lineNum">      28 </span>                :            :  * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
<span class="lineNum">      29 </span>                :            :  * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
<span class="lineNum">      30 </span>                :            :  * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
<span class="lineNum">      31 </span>                :            :  * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
<span class="lineNum">      32 </span>                :            :  * OF THESE LICENSED DELIVERABLES.
<span class="lineNum">      33 </span>                :            :  *
<span class="lineNum">      34 </span>                :            :  * U.S. Government End Users.  These Licensed Deliverables are a
<span class="lineNum">      35 </span>                :            :  * &quot;commercial item&quot; as that term is defined at 48 C.F.R. 2.101 (OCT
<span class="lineNum">      36 </span>                :            :  * 1995), consisting of &quot;commercial computer software&quot; and &quot;commercial
<span class="lineNum">      37 </span>                :            :  * computer software documentation&quot; as such terms are used in 48
<span class="lineNum">      38 </span>                :            :  * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
<span class="lineNum">      39 </span>                :            :  * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
<span class="lineNum">      40 </span>                :            :  * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
<span class="lineNum">      41 </span>                :            :  * U.S. Government End Users acquire the Licensed Deliverables with
<span class="lineNum">      42 </span>                :            :  * only those rights set forth herein.
<span class="lineNum">      43 </span>                :            :  *
<span class="lineNum">      44 </span>                :            :  * Any use of the Licensed Deliverables in individual and commercial
<span class="lineNum">      45 </span>                :            :  * software must include, in the user documentation and internal
<span class="lineNum">      46 </span>                :            :  * comments to the code, the above Disclaimer and U.S. Government End
<span class="lineNum">      47 </span>                :            :  * Users Notice.
<span class="lineNum">      48 </span>                :            :  */
<span class="lineNum">      49 </span>                :            : 
<span class="lineNum">      50 </span>                :            : #if !defined(__CUDA_RUNTIME_H__)
<span class="lineNum">      51 </span>                :            : #define __CUDA_RUNTIME_H__
<span class="lineNum">      52 </span>                :            : 
<span class="lineNum">      53 </span>                :            : #if !defined(__CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__)
<span class="lineNum">      54 </span>                :            : #define __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__
<span class="lineNum">      55 </span>                :            : #define __UNDEF_CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS_CUDA_RUNTIME_H__
<span class="lineNum">      56 </span>                :            : #endif
<span class="lineNum">      57 </span>                :            : 
<span class="lineNum">      58 </span>                :            : #if !defined(__CUDACC_RTC__)
<span class="lineNum">      59 </span>                :            : #if defined(__GNUC__)
<span class="lineNum">      60 </span>                :            : #if defined(__clang__) || (!defined(__PGIC__) &amp;&amp; (__GNUC__ &gt; 4 || (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt;= 6)))
<span class="lineNum">      61 </span>                :            : #pragma GCC diagnostic push
<span class="lineNum">      62 </span>                :            : #endif
<span class="lineNum">      63 </span>                :            : #if defined(__clang__) || (!defined(__PGIC__) &amp;&amp; (__GNUC__ &gt; 4 || (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt;= 2)))
<span class="lineNum">      64 </span>                :            : #pragma GCC diagnostic ignored &quot;-Wunused-function&quot;
<span class="lineNum">      65 </span>                :            : #endif
<span class="lineNum">      66 </span>                :            : #elif defined(_MSC_VER)
<span class="lineNum">      67 </span>                :            : #pragma warning(push)
<span class="lineNum">      68 </span>                :            : #pragma warning(disable: 4820)
<span class="lineNum">      69 </span>                :            : #endif
<span class="lineNum">      70 </span>                :            : #endif
<span class="lineNum">      71 </span>                :            : 
<span class="lineNum">      72 </span>                :            : #ifdef __QNX__
<span class="lineNum">      73 </span>                :            : #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt;= 7)
<span class="lineNum">      74 </span>                :            : typedef unsigned size_t;
<span class="lineNum">      75 </span>                :            : #endif
<span class="lineNum">      76 </span>                :            : #endif
<span class="lineNum">      77 </span>                :            : /*******************************************************************************
<span class="lineNum">      78 </span>                :            : *                                                                              *
<span class="lineNum">      79 </span>                :            : *                                                                              *
<span class="lineNum">      80 </span>                :            : *                                                                              *
<span class="lineNum">      81 </span>                :            : *******************************************************************************/
<span class="lineNum">      82 </span>                :            : 
<span class="lineNum">      83 </span>                :            : #include &quot;crt/host_config.h&quot;
<span class="lineNum">      84 </span>                :            : 
<span class="lineNum">      85 </span>                :            : /*******************************************************************************
<span class="lineNum">      86 </span>                :            : *                                                                              *
<span class="lineNum">      87 </span>                :            : *                                                                              *
<span class="lineNum">      88 </span>                :            : *                                                                              *
<span class="lineNum">      89 </span>                :            : *******************************************************************************/
<span class="lineNum">      90 </span>                :            : 
<span class="lineNum">      91 </span>                :            : #include &quot;builtin_types.h&quot;
<span class="lineNum">      92 </span>                :            : #include &quot;library_types.h&quot;
<span class="lineNum">      93 </span>                :            : #if !defined(__CUDACC_RTC__)
<span class="lineNum">      94 </span>                :            : #define EXCLUDE_FROM_RTC
<span class="lineNum">      95 </span>                :            : #include &quot;channel_descriptor.h&quot;
<span class="lineNum">      96 </span>                :            : #include &quot;cuda_runtime_api.h&quot;
<span class="lineNum">      97 </span>                :            : #include &quot;driver_functions.h&quot;
<span class="lineNum">      98 </span>                :            : #undef EXCLUDE_FROM_RTC
<span class="lineNum">      99 </span>                :            : #endif /* !__CUDACC_RTC__ */
<span class="lineNum">     100 </span>                :            : #include &quot;crt/host_defines.h&quot;
<span class="lineNum">     101 </span>                :            : #include &quot;vector_functions.h&quot;
<span class="lineNum">     102 </span>                :            : 
<span class="lineNum">     103 </span>                :            : #if defined(__CUDACC__)
<span class="lineNum">     104 </span>                :            : 
<span class="lineNum">     105 </span>                :            : #if defined(__CUDACC_RTC__)
<span class="lineNum">     106 </span>                :            : #include &quot;nvrtc_device_runtime.h&quot;
<span class="lineNum">     107 </span>                :            : #include &quot;crt/device_functions.h&quot;
<span class="lineNum">     108 </span>                :            : 
<span class="lineNum">     109 </span>                :            : extern __host__ __device__  unsigned cudaConfigureCall(dim3 gridDim, 
<span class="lineNum">     110 </span>                :            :                                       dim3 blockDim, 
<span class="lineNum">     111 </span>                :            :                                       size_t sharedMem = 0, 
<span class="lineNum">     112 </span>                :            :                                       void *stream = 0);
<span class="lineNum">     113 </span>                :            : #include &quot;crt/common_functions.h&quot;
<span class="lineNum">     114 </span>                :            : #include &quot;cuda_surface_types.h&quot;
<span class="lineNum">     115 </span>                :            : #include &quot;cuda_texture_types.h&quot;
<span class="lineNum">     116 </span>                :            : #include &quot;device_launch_parameters.h&quot;
<span class="lineNum">     117 </span>                :            : 
<span class="lineNum">     118 </span>                :            : #else /* !__CUDACC_RTC__ */
<span class="lineNum">     119 </span>                :            : #define EXCLUDE_FROM_RTC
<span class="lineNum">     120 </span>                :            : #include &quot;crt/common_functions.h&quot;
<span class="lineNum">     121 </span>                :            : #include &quot;cuda_surface_types.h&quot;
<span class="lineNum">     122 </span>                :            : #include &quot;cuda_texture_types.h&quot;
<span class="lineNum">     123 </span>                :            : #include &quot;crt/device_functions.h&quot;
<span class="lineNum">     124 </span>                :            : #include &quot;device_launch_parameters.h&quot;
<span class="lineNum">     125 </span>                :            : 
<span class="lineNum">     126 </span>                :            : #if defined(__CUDACC_EXTENDED_LAMBDA__)
<span class="lineNum">     127 </span>                :            : #include &lt;functional&gt;
<span class="lineNum">     128 </span>                :            : #include &lt;utility&gt;
<span class="lineNum">     129 </span>                :            : struct  __device_builtin__ __nv_lambda_preheader_injection { };
<span class="lineNum">     130 </span>                :            : #endif /* defined(__CUDACC_EXTENDED_LAMBDA__) */
<span class="lineNum">     131 </span>                :            : 
<span class="lineNum">     132 </span>                :            : #undef EXCLUDE_FROM_RTC
<span class="lineNum">     133 </span>                :            : #endif /* __CUDACC_RTC__ */
<span class="lineNum">     134 </span>                :            : 
<span class="lineNum">     135 </span>                :            : #endif /* __CUDACC__ */
<span class="lineNum">     136 </span>                :            : 
<span class="lineNum">     137 </span>                :            : #if defined(__cplusplus) &amp;&amp; !defined(__CUDACC_RTC__)
<span class="lineNum">     138 </span>                :            : 
<span class="lineNum">     139 </span>                :            : /*******************************************************************************
<span class="lineNum">     140 </span>                :            : *                                                                              *
<span class="lineNum">     141 </span>                :            : *                                                                              *
<span class="lineNum">     142 </span>                :            : *                                                                              *
<span class="lineNum">     143 </span>                :            : *******************************************************************************/
<span class="lineNum">     144 </span>                :            : 
<span class="lineNum">     145 </span>                :            : /**
<span class="lineNum">     146 </span>                :            :  * \addtogroup CUDART_HIGHLEVEL
<span class="lineNum">     147 </span>                :            :  * @{
<span class="lineNum">     148 </span>                :            :  */
<span class="lineNum">     149 </span>                :            : 
<span class="lineNum">     150 </span>                :            : /**
<span class="lineNum">     151 </span>                :            :  *\brief Launches a device function
<span class="lineNum">     152 </span>                :            :  *
<span class="lineNum">     153 </span>                :            :  * The function invokes kernel \p func on \p gridDim (\p gridDim.x × \p gridDim.y
<span class="lineNum">     154 </span>                :            :  * × \p gridDim.z) grid of blocks. Each block contains \p blockDim (\p blockDim.x ×
<span class="lineNum">     155 </span>                :            :  * \p blockDim.y × \p blockDim.z) threads.
<span class="lineNum">     156 </span>                :            :  *
<span class="lineNum">     157 </span>                :            :  * If the kernel has N parameters the \p args should point to array of N pointers.
<span class="lineNum">     158 </span>                :            :  * Each pointer, from &lt;tt&gt;args[0]&lt;/tt&gt; to &lt;tt&gt;args[N - 1]&lt;/tt&gt;, point to the region
<span class="lineNum">     159 </span>                :            :  * of memory from which the actual parameter will be copied.
<span class="lineNum">     160 </span>                :            :  *
<span class="lineNum">     161 </span>                :            :  * \p sharedMem sets the amount of dynamic shared memory that will be available to
<span class="lineNum">     162 </span>                :            :  * each thread block.
<span class="lineNum">     163 </span>                :            :  *
<span class="lineNum">     164 </span>                :            :  * \p stream specifies a stream the invocation is associated to.
<span class="lineNum">     165 </span>                :            :  *
<span class="lineNum">     166 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">     167 </span>                :            :  * \param gridDim     - Grid dimentions
<span class="lineNum">     168 </span>                :            :  * \param blockDim    - Block dimentions
<span class="lineNum">     169 </span>                :            :  * \param args        - Arguments
<span class="lineNum">     170 </span>                :            :  * \param sharedMem   - Shared memory (defaults to 0)
<span class="lineNum">     171 </span>                :            :  * \param stream      - Stream identifier (defaults to NULL)
<span class="lineNum">     172 </span>                :            :  *
<span class="lineNum">     173 </span>                :            :  * \return
<span class="lineNum">     174 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     175 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">     176 </span>                :            :  * ::cudaErrorInvalidConfiguration,
<span class="lineNum">     177 </span>                :            :  * ::cudaErrorLaunchFailure,
<span class="lineNum">     178 </span>                :            :  * ::cudaErrorLaunchTimeout,
<span class="lineNum">     179 </span>                :            :  * ::cudaErrorLaunchOutOfResources,
<span class="lineNum">     180 </span>                :            :  * ::cudaErrorSharedObjectInitFailed,
<span class="lineNum">     181 </span>                :            :  * ::cudaErrorInvalidPtx,
<span class="lineNum">     182 </span>                :            :  * ::cudaErrorNoKernelImageForDevice,
<span class="lineNum">     183 </span>                :            :  * ::cudaErrorJitCompilerNotFound
<span class="lineNum">     184 </span>                :            :  * \notefnerr
<span class="lineNum">     185 </span>                :            :  * \note_async
<span class="lineNum">     186 </span>                :            :  * \note_null_stream
<span class="lineNum">     187 </span>                :            :  * \note_init_rt
<span class="lineNum">     188 </span>                :            :  * \note_callback
<span class="lineNum">     189 </span>                :            :  *
<span class="lineNum">     190 </span>                :            :  * \ref ::cudaLaunchKernel(const void *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C API)&quot;
<span class="lineNum">     191 </span>                :            :  */
<span class="lineNum">     192 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     193 </span>                :            : static __inline__ __host__ cudaError_t cudaLaunchKernel(
<span class="lineNum">     194 </span>                :            :   const T *func,
<span class="lineNum">     195 </span>                :            :   dim3 gridDim,
<span class="lineNum">     196 </span>                :            :   dim3 blockDim,
<span class="lineNum">     197 </span>                :            :   void **args,
<span class="lineNum">     198 </span>                :            :   size_t sharedMem = 0,
<span class="lineNum">     199 </span>                :            :   cudaStream_t stream = 0
<span class="lineNum">     200 </span>                :            : )
<span class="lineNum">     201 </span>                :            : {
<span class="lineNum">     202 </span>                :            :     return ::cudaLaunchKernel((const void *)func, gridDim, blockDim, args, sharedMem, stream);
<span class="lineNum">     203 </span>                :            : }
<span class="lineNum">     204 </span>                :            : 
<span class="lineNum">     205 </span>                :            : /**
<span class="lineNum">     206 </span>                :            :  *\brief Launches a device function
<span class="lineNum">     207 </span>                :            :  *
<span class="lineNum">     208 </span>                :            :  * The function invokes kernel \p func on \p gridDim (\p gridDim.x × \p gridDim.y
<span class="lineNum">     209 </span>                :            :  * × \p gridDim.z) grid of blocks. Each block contains \p blockDim (\p blockDim.x ×
<span class="lineNum">     210 </span>                :            :  * \p blockDim.y × \p blockDim.z) threads.
<span class="lineNum">     211 </span>                :            :  *
<span class="lineNum">     212 </span>                :            :  * The device on which this kernel is invoked must have a non-zero value for
<span class="lineNum">     213 </span>                :            :  * the device attribute ::cudaDevAttrCooperativeLaunch.
<span class="lineNum">     214 </span>                :            :  *
<span class="lineNum">     215 </span>                :            :  * The total number of blocks launched cannot exceed the maximum number of blocks per
<span class="lineNum">     216 </span>                :            :  * multiprocessor as returned by ::cudaOccupancyMaxActiveBlocksPerMultiprocessor (or
<span class="lineNum">     217 </span>                :            :  * ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) times the number of multiprocessors
<span class="lineNum">     218 </span>                :            :  * as specified by the device attribute ::cudaDevAttrMultiProcessorCount.
<span class="lineNum">     219 </span>                :            :  *
<span class="lineNum">     220 </span>                :            :  * The kernel cannot make use of CUDA dynamic parallelism.
<span class="lineNum">     221 </span>                :            :  *
<span class="lineNum">     222 </span>                :            :  * If the kernel has N parameters the \p args should point to array of N pointers.
<span class="lineNum">     223 </span>                :            :  * Each pointer, from &lt;tt&gt;args[0]&lt;/tt&gt; to &lt;tt&gt;args[N - 1]&lt;/tt&gt;, point to the region
<span class="lineNum">     224 </span>                :            :  * of memory from which the actual parameter will be copied.
<span class="lineNum">     225 </span>                :            :  *
<span class="lineNum">     226 </span>                :            :  * \p sharedMem sets the amount of dynamic shared memory that will be available to
<span class="lineNum">     227 </span>                :            :  * each thread block.
<span class="lineNum">     228 </span>                :            :  *
<span class="lineNum">     229 </span>                :            :  * \p stream specifies a stream the invocation is associated to.
<span class="lineNum">     230 </span>                :            :  *
<span class="lineNum">     231 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">     232 </span>                :            :  * \param gridDim     - Grid dimentions
<span class="lineNum">     233 </span>                :            :  * \param blockDim    - Block dimentions
<span class="lineNum">     234 </span>                :            :  * \param args        - Arguments
<span class="lineNum">     235 </span>                :            :  * \param sharedMem   - Shared memory (defaults to 0)
<span class="lineNum">     236 </span>                :            :  * \param stream      - Stream identifier (defaults to NULL)
<span class="lineNum">     237 </span>                :            :  *
<span class="lineNum">     238 </span>                :            :  * \return
<span class="lineNum">     239 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     240 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">     241 </span>                :            :  * ::cudaErrorInvalidConfiguration,
<span class="lineNum">     242 </span>                :            :  * ::cudaErrorLaunchFailure,
<span class="lineNum">     243 </span>                :            :  * ::cudaErrorLaunchTimeout,
<span class="lineNum">     244 </span>                :            :  * ::cudaErrorLaunchOutOfResources,
<span class="lineNum">     245 </span>                :            :  * ::cudaErrorSharedObjectInitFailed
<span class="lineNum">     246 </span>                :            :  * \notefnerr
<span class="lineNum">     247 </span>                :            :  * \note_async
<span class="lineNum">     248 </span>                :            :  * \note_null_stream
<span class="lineNum">     249 </span>                :            :  * \note_init_rt
<span class="lineNum">     250 </span>                :            :  * \note_callback
<span class="lineNum">     251 </span>                :            :  *
<span class="lineNum">     252 </span>                :            :  * \ref ::cudaLaunchCooperativeKernel(const void *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchCooperativeKernel (C API)&quot;
<span class="lineNum">     253 </span>                :            :  */
<span class="lineNum">     254 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     255 </span>                :            : static __inline__ __host__ cudaError_t cudaLaunchCooperativeKernel(
<span class="lineNum">     256 </span>                :            :   const T *func,
<span class="lineNum">     257 </span>                :            :   dim3 gridDim,
<span class="lineNum">     258 </span>                :            :   dim3 blockDim,
<span class="lineNum">     259 </span>                :            :   void **args,
<span class="lineNum">     260 </span>                :            :   size_t sharedMem = 0,
<span class="lineNum">     261 </span>                :            :   cudaStream_t stream = 0
<span class="lineNum">     262 </span>                :            : )
<span class="lineNum">     263 </span>                :            : {
<span class="lineNum">     264 </span>                :            :     return ::cudaLaunchCooperativeKernel((const void *)func, gridDim, blockDim, args, sharedMem, stream);
<span class="lineNum">     265 </span>                :            : }
<span class="lineNum">     266 </span>                :            : 
<span class="lineNum">     267 </span>                :            : /**
<span class="lineNum">     268 </span>                :            :  * \brief \hl Configure a device launch
<span class="lineNum">     269 </span>                :            :  *
<span class="lineNum">     270 </span>                :            :  * \deprecated This function is deprecated as of CUDA 7.0
<span class="lineNum">     271 </span>                :            :  *
<span class="lineNum">     272 </span>                :            :  * Pushes \p size bytes of the argument pointed to by \p arg at \p offset
<span class="lineNum">     273 </span>                :            :  * bytes from the start of the parameter passing area, which starts at
<span class="lineNum">     274 </span>                :            :  * offset 0. The arguments are stored in the top of the execution stack.
<span class="lineNum">     275 </span>                :            :  * \ref ::cudaSetupArgument(T, size_t) &quot;cudaSetupArgument()&quot; must be preceded
<span class="lineNum">     276 </span>                :            :  * by a call to ::cudaConfigureCall().
<span class="lineNum">     277 </span>                :            :  *
<span class="lineNum">     278 </span>                :            :  * \param arg    - Argument to push for a kernel launch
<span class="lineNum">     279 </span>                :            :  * \param offset - Offset in argument stack to push new arg
<span class="lineNum">     280 </span>                :            :  *
<span class="lineNum">     281 </span>                :            :  * \return
<span class="lineNum">     282 </span>                :            :  * ::cudaSuccess
<span class="lineNum">     283 </span>                :            :  * \notefnerr
<span class="lineNum">     284 </span>                :            :  * \note_init_rt
<span class="lineNum">     285 </span>                :            :  * \note_callback
<span class="lineNum">     286 </span>                :            :  *
<span class="lineNum">     287 </span>                :            :  * \ref ::cudaLaunchKernel(const T *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C++ API)&quot;,
<span class="lineNum">     288 </span>                :            :  * \ref ::cudaFuncGetAttributes(struct cudaFuncAttributes*, T*) &quot;cudaFuncGetAttributes (C++ API)&quot;,
<span class="lineNum">     289 </span>                :            :  * \ref ::cudaLaunch(T*) &quot;cudaLaunch (C++ API)&quot;,
<span class="lineNum">     290 </span>                :            :  * ::cudaSetDoubleForDevice,
<span class="lineNum">     291 </span>                :            :  * ::cudaSetDoubleForHost,
<span class="lineNum">     292 </span>                :            :  * \ref ::cudaSetupArgument(const void*, size_t, size_t) &quot;cudaSetupArgument (C API)&quot;
<span class="lineNum">     293 </span>                :            :  */
<span class="lineNum">     294 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     295 </span>                :            : static __inline__ __host__ cudaError_t cudaSetupArgument(
<span class="lineNum">     296 </span>                :            :   T      arg,
<span class="lineNum">     297 </span>                :            :   size_t offset
<span class="lineNum">     298 </span>                :            : )
<span class="lineNum">     299 </span>                :            : {
<span class="lineNum">     300 </span>                :            :   return ::cudaSetupArgument((const void*)&amp;arg, sizeof(T), offset);
<span class="lineNum">     301 </span>                :            : }
<span class="lineNum">     302 </span>                :            : 
<span class="lineNum">     303 </span>                :            : /**
<span class="lineNum">     304 </span>                :            :  * \brief \hl Creates an event object with the specified flags
<span class="lineNum">     305 </span>                :            :  *
<span class="lineNum">     306 </span>                :            :  * Creates an event object with the specified flags. Valid flags include:
<span class="lineNum">     307 </span>                :            :  * - ::cudaEventDefault: Default event creation flag.
<span class="lineNum">     308 </span>                :            :  * - ::cudaEventBlockingSync: Specifies that event should use blocking
<span class="lineNum">     309 </span>                :            :  *   synchronization. A host thread that uses ::cudaEventSynchronize() to wait
<span class="lineNum">     310 </span>                :            :  *   on an event created with this flag will block until the event actually
<span class="lineNum">     311 </span>                :            :  *   completes.
<span class="lineNum">     312 </span>                :            :  * - ::cudaEventDisableTiming: Specifies that the created event does not need
<span class="lineNum">     313 </span>                :            :  *   to record timing data.  Events created with this flag specified and
<span class="lineNum">     314 </span>                :            :  *   the ::cudaEventBlockingSync flag not specified will provide the best
<span class="lineNum">     315 </span>                :            :  *   performance when used with ::cudaStreamWaitEvent() and ::cudaEventQuery().
<span class="lineNum">     316 </span>                :            :  *
<span class="lineNum">     317 </span>                :            :  * \param event - Newly created event
<span class="lineNum">     318 </span>                :            :  * \param flags - Flags for new event
<span class="lineNum">     319 </span>                :            :  *
<span class="lineNum">     320 </span>                :            :  * \return
<span class="lineNum">     321 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     322 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     323 </span>                :            :  * ::cudaErrorLaunchFailure,
<span class="lineNum">     324 </span>                :            :  * ::cudaErrorMemoryAllocation
<span class="lineNum">     325 </span>                :            :  * \notefnerr
<span class="lineNum">     326 </span>                :            :  * \note_init_rt
<span class="lineNum">     327 </span>                :            :  * \note_callback
<span class="lineNum">     328 </span>                :            :  *
<span class="lineNum">     329 </span>                :            :  * \sa \ref ::cudaEventCreate(cudaEvent_t*) &quot;cudaEventCreate (C API)&quot;,
<span class="lineNum">     330 </span>                :            :  * ::cudaEventCreateWithFlags, ::cudaEventRecord, ::cudaEventQuery,
<span class="lineNum">     331 </span>                :            :  * ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventElapsedTime,
<span class="lineNum">     332 </span>                :            :  * ::cudaStreamWaitEvent
<span class="lineNum">     333 </span>                :            :  */
<span class="lineNum">     334 </span>                :            : static __inline__ __host__ cudaError_t cudaEventCreate(
<span class="lineNum">     335 </span>                :            :   cudaEvent_t  *event,
<span class="lineNum">     336 </span>                :            :   unsigned int  flags
<span class="lineNum">     337 </span>                :            : )
<span class="lineNum">     338 </span>                :            : {
<span class="lineNum">     339 </span>                :            :   return ::cudaEventCreateWithFlags(event, flags);
<span class="lineNum">     340 </span>                :            : }
<span class="lineNum">     341 </span>                :            : 
<span class="lineNum">     342 </span>                :            : /**
<span class="lineNum">     343 </span>                :            :  * \brief \hl Allocates page-locked memory on the host
<span class="lineNum">     344 </span>                :            :  *
<span class="lineNum">     345 </span>                :            :  * Allocates \p size bytes of host memory that is page-locked and accessible
<span class="lineNum">     346 </span>                :            :  * to the device. The driver tracks the virtual memory ranges allocated with
<span class="lineNum">     347 </span>                :            :  * this function and automatically accelerates calls to functions such as
<span class="lineNum">     348 </span>                :            :  * ::cudaMemcpy(). Since the memory can be accessed directly by the device, it
<span class="lineNum">     349 </span>                :            :  * can be read or written with much higher bandwidth than pageable memory
<span class="lineNum">     350 </span>                :            :  * obtained with functions such as ::malloc(). Allocating excessive amounts of
<span class="lineNum">     351 </span>                :            :  * pinned memory may degrade system performance, since it reduces the amount
<span class="lineNum">     352 </span>                :            :  * of memory available to the system for paging. As a result, this function is
<span class="lineNum">     353 </span>                :            :  * best used sparingly to allocate staging areas for data exchange between host
<span class="lineNum">     354 </span>                :            :  * and device.
<span class="lineNum">     355 </span>                :            :  *
<span class="lineNum">     356 </span>                :            :  * The \p flags parameter enables different options to be specified that affect
<span class="lineNum">     357 </span>                :            :  * the allocation, as follows.
<span class="lineNum">     358 </span>                :            :  * - ::cudaHostAllocDefault: This flag's value is defined to be 0.
<span class="lineNum">     359 </span>                :            :  * - ::cudaHostAllocPortable: The memory returned by this call will be
<span class="lineNum">     360 </span>                :            :  * considered as pinned memory by all CUDA contexts, not just the one that
<span class="lineNum">     361 </span>                :            :  * performed the allocation.
<span class="lineNum">     362 </span>                :            :  * - ::cudaHostAllocMapped: Maps the allocation into the CUDA address space.
<span class="lineNum">     363 </span>                :            :  * The device pointer to the memory may be obtained by calling
<span class="lineNum">     364 </span>                :            :  * ::cudaHostGetDevicePointer().
<span class="lineNum">     365 </span>                :            :  * - ::cudaHostAllocWriteCombined: Allocates the memory as write-combined (WC).
<span class="lineNum">     366 </span>                :            :  * WC memory can be transferred across the PCI Express bus more quickly on some
<span class="lineNum">     367 </span>                :            :  * system configurations, but cannot be read efficiently by most CPUs.  WC
<span class="lineNum">     368 </span>                :            :  * memory is a good option for buffers that will be written by the CPU and read
<span class="lineNum">     369 </span>                :            :  * by the device via mapped pinned memory or host-&gt;device transfers.
<span class="lineNum">     370 </span>                :            :  *
<span class="lineNum">     371 </span>                :            :  * All of these flags are orthogonal to one another: a developer may allocate
<span class="lineNum">     372 </span>                :            :  * memory that is portable, mapped and/or write-combined with no restrictions.
<span class="lineNum">     373 </span>                :            :  *
<span class="lineNum">     374 </span>                :            :  * ::cudaSetDeviceFlags() must have been called with the ::cudaDeviceMapHost
<span class="lineNum">     375 </span>                :            :  * flag in order for the ::cudaHostAllocMapped flag to have any effect.
<span class="lineNum">     376 </span>                :            :  *
<span class="lineNum">     377 </span>                :            :  * The ::cudaHostAllocMapped flag may be specified on CUDA contexts for devices
<span class="lineNum">     378 </span>                :            :  * that do not support mapped pinned memory. The failure is deferred to
<span class="lineNum">     379 </span>                :            :  * ::cudaHostGetDevicePointer() because the memory may be mapped into other
<span class="lineNum">     380 </span>                :            :  * CUDA contexts via the ::cudaHostAllocPortable flag.
<span class="lineNum">     381 </span>                :            :  *
<span class="lineNum">     382 </span>                :            :  * Memory allocated by this function must be freed with ::cudaFreeHost().
<span class="lineNum">     383 </span>                :            :  *
<span class="lineNum">     384 </span>                :            :  * \param ptr   - Device pointer to allocated memory
<span class="lineNum">     385 </span>                :            :  * \param size  - Requested allocation size in bytes
<span class="lineNum">     386 </span>                :            :  * \param flags - Requested properties of allocated memory
<span class="lineNum">     387 </span>                :            :  *
<span class="lineNum">     388 </span>                :            :  * \return
<span class="lineNum">     389 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     390 </span>                :            :  * ::cudaErrorMemoryAllocation
<span class="lineNum">     391 </span>                :            :  * \notefnerr
<span class="lineNum">     392 </span>                :            :  * \note_init_rt
<span class="lineNum">     393 </span>                :            :  * \note_callback
<span class="lineNum">     394 </span>                :            :  *
<span class="lineNum">     395 </span>                :            :  * \sa ::cudaSetDeviceFlags,
<span class="lineNum">     396 </span>                :            :  * \ref ::cudaMallocHost(void**, size_t) &quot;cudaMallocHost (C API)&quot;,
<span class="lineNum">     397 </span>                :            :  * ::cudaFreeHost, ::cudaHostAlloc
<span class="lineNum">     398 </span>                :            :  */
<span class="lineNum">     399 </span>                :            : static __inline__ __host__ cudaError_t cudaMallocHost(
<span class="lineNum">     400 </span>                :            :   void         **ptr,
<span class="lineNum">     401 </span>                :            :   size_t         size,
<span class="lineNum">     402 </span>                :            :   unsigned int   flags
<span class="lineNum">     403 </span>                :            : )
<span class="lineNum">     404 </span>                :            : {
<span class="lineNum">     405 </span>                :            :   return ::cudaHostAlloc(ptr, size, flags);
<span class="lineNum">     406 </span>                :            : }
<span class="lineNum">     407 </span>                :            : 
<span class="lineNum">     408 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     409 </span>                :            : static __inline__ __host__ cudaError_t cudaHostAlloc(
<span class="lineNum">     410 </span>                :            :   T            **ptr,
<span class="lineNum">     411 </span>                :            :   size_t         size,
<span class="lineNum">     412 </span>                :            :   unsigned int   flags
<span class="lineNum">     413 </span>                :            : )
<span class="lineNum">     414 </span>                :            : {
<span class="lineNum">     415 </span>                :            :   return ::cudaHostAlloc((void**)(void*)ptr, size, flags);
<span class="lineNum">     416 </span>                :            : }
<span class="lineNum">     417 </span>                :            : 
<span class="lineNum">     418 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     419 </span>                :            : static __inline__ __host__ cudaError_t cudaHostGetDevicePointer(
<span class="lineNum">     420 </span>                :            :   T            **pDevice,
<span class="lineNum">     421 </span>                :            :   void          *pHost,
<span class="lineNum">     422 </span>                :            :   unsigned int   flags
<span class="lineNum">     423 </span>                :            : )
<span class="lineNum">     424 </span>                :            : {
<span class="lineNum">     425 </span>                :            :   return ::cudaHostGetDevicePointer((void**)(void*)pDevice, pHost, flags);
<span class="lineNum">     426 </span>                :            : }
<span class="lineNum">     427 </span>                :            : 
<span class="lineNum">     428 </span>                :            : /**
<span class="lineNum">     429 </span>                :            :  * \brief Allocates memory that will be automatically managed by the Unified Memory system
<span class="lineNum">     430 </span>                :            :  *
<span class="lineNum">     431 </span>                :            :  * Allocates \p size bytes of managed memory on the device and returns in
<span class="lineNum">     432 </span>                :            :  * \p *devPtr a pointer to the allocated memory. If the device doesn't support
<span class="lineNum">     433 </span>                :            :  * allocating managed memory, ::cudaErrorNotSupported is returned. Support
<span class="lineNum">     434 </span>                :            :  * for managed memory can be queried using the device attribute
<span class="lineNum">     435 </span>                :            :  * ::cudaDevAttrManagedMemory. The allocated memory is suitably
<span class="lineNum">     436 </span>                :            :  * aligned for any kind of variable. The memory is not cleared. If \p size
<span class="lineNum">     437 </span>                :            :  * is 0, ::cudaMallocManaged returns ::cudaErrorInvalidValue. The pointer
<span class="lineNum">     438 </span>                :            :  * is valid on the CPU and on all GPUs in the system that support managed memory.
<span class="lineNum">     439 </span>                :            :  * All accesses to this pointer must obey the Unified Memory programming model.
<span class="lineNum">     440 </span>                :            :  *
<span class="lineNum">     441 </span>                :            :  * \p flags specifies the default stream association for this allocation.
<span class="lineNum">     442 </span>                :            :  * \p flags must be one of ::cudaMemAttachGlobal or ::cudaMemAttachHost. The
<span class="lineNum">     443 </span>                :            :  * default value for \p flags is ::cudaMemAttachGlobal.
<span class="lineNum">     444 </span>                :            :  * If ::cudaMemAttachGlobal is specified, then this memory is accessible from
<span class="lineNum">     445 </span>                :            :  * any stream on any device. If ::cudaMemAttachHost is specified, then the
<span class="lineNum">     446 </span>                :            :  * allocation should not be accessed from devices that have a zero value for the
<span class="lineNum">     447 </span>                :            :  * device attribute ::cudaDevAttrConcurrentManagedAccess; an explicit call to
<span class="lineNum">     448 </span>                :            :  * ::cudaStreamAttachMemAsync will be required to enable access on such devices.
<span class="lineNum">     449 </span>                :            :  *
<span class="lineNum">     450 </span>                :            :  * If the association is later changed via ::cudaStreamAttachMemAsync to
<span class="lineNum">     451 </span>                :            :  * a single stream, the default association, as specifed during ::cudaMallocManaged,
<span class="lineNum">     452 </span>                :            :  * is restored when that stream is destroyed. For __managed__ variables, the
<span class="lineNum">     453 </span>                :            :  * default association is always ::cudaMemAttachGlobal. Note that destroying a
<span class="lineNum">     454 </span>                :            :  * stream is an asynchronous operation, and as a result, the change to default
<span class="lineNum">     455 </span>                :            :  * association won't happen until all work in the stream has completed.
<span class="lineNum">     456 </span>                :            :  *
<span class="lineNum">     457 </span>                :            :  * Memory allocated with ::cudaMallocManaged should be released with ::cudaFree.
<span class="lineNum">     458 </span>                :            :  *
<span class="lineNum">     459 </span>                :            :  * Device memory oversubscription is possible for GPUs that have a non-zero value for the
<span class="lineNum">     460 </span>                :            :  * device attribute ::cudaDevAttrConcurrentManagedAccess. Managed memory on
<span class="lineNum">     461 </span>                :            :  * such GPUs may be evicted from device memory to host memory at any time by the Unified
<span class="lineNum">     462 </span>                :            :  * Memory driver in order to make room for other allocations.
<span class="lineNum">     463 </span>                :            :  *
<span class="lineNum">     464 </span>                :            :  * In a multi-GPU system where all GPUs have a non-zero value for the device attribute
<span class="lineNum">     465 </span>                :            :  * ::cudaDevAttrConcurrentManagedAccess, managed memory may not be populated when this
<span class="lineNum">     466 </span>                :            :  * API returns and instead may be populated on access. In such systems, managed memory can
<span class="lineNum">     467 </span>                :            :  * migrate to any processor's memory at any time. The Unified Memory driver will employ heuristics to
<span class="lineNum">     468 </span>                :            :  * maintain data locality and prevent excessive page faults to the extent possible. The application
<span class="lineNum">     469 </span>                :            :  * can also guide the driver about memory usage patterns via ::cudaMemAdvise. The application
<span class="lineNum">     470 </span>                :            :  * can also explicitly migrate memory to a desired processor's memory via
<span class="lineNum">     471 </span>                :            :  * ::cudaMemPrefetchAsync.
<span class="lineNum">     472 </span>                :            :  *
<span class="lineNum">     473 </span>                :            :  * In a multi-GPU system where all of the GPUs have a zero value for the device attribute
<span class="lineNum">     474 </span>                :            :  * ::cudaDevAttrConcurrentManagedAccess and all the GPUs have peer-to-peer support
<span class="lineNum">     475 </span>                :            :  * with each other, the physical storage for managed memory is created on the GPU which is active
<span class="lineNum">     476 </span>                :            :  * at the time ::cudaMallocManaged is called. All other GPUs will reference the data at reduced
<span class="lineNum">     477 </span>                :            :  * bandwidth via peer mappings over the PCIe bus. The Unified Memory driver does not migrate
<span class="lineNum">     478 </span>                :            :  * memory among such GPUs.
<span class="lineNum">     479 </span>                :            :  *
<span class="lineNum">     480 </span>                :            :  * In a multi-GPU system where not all GPUs have peer-to-peer support with each other and
<span class="lineNum">     481 </span>                :            :  * where the value of the device attribute ::cudaDevAttrConcurrentManagedAccess
<span class="lineNum">     482 </span>                :            :  * is zero for at least one of those GPUs, the location chosen for physical storage of managed
<span class="lineNum">     483 </span>                :            :  * memory is system-dependent.
<span class="lineNum">     484 </span>                :            :  * - On Linux, the location chosen will be device memory as long as the current set of active
<span class="lineNum">     485 </span>                :            :  * contexts are on devices that either have peer-to-peer support with each other or have a
<span class="lineNum">     486 </span>                :            :  * non-zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess.
<span class="lineNum">     487 </span>                :            :  * If there is an active context on a GPU that does not have a non-zero value for that device
<span class="lineNum">     488 </span>                :            :  * attribute and it does not have peer-to-peer support with the other devices that have active
<span class="lineNum">     489 </span>                :            :  * contexts on them, then the location for physical storage will be 'zero-copy' or host memory.
<span class="lineNum">     490 </span>                :            :  * Note that this means that managed memory that is located in device memory is migrated to
<span class="lineNum">     491 </span>                :            :  * host memory if a new context is created on a GPU that doesn't have a non-zero value for
<span class="lineNum">     492 </span>                :            :  * the device attribute and does not support peer-to-peer with at least one of the other devices
<span class="lineNum">     493 </span>                :            :  * that has an active context. This in turn implies that context creation may fail if there is
<span class="lineNum">     494 </span>                :            :  * insufficient host memory to migrate all managed allocations.
<span class="lineNum">     495 </span>                :            :  * - On Windows, the physical storage is always created in 'zero-copy' or host memory.
<span class="lineNum">     496 </span>                :            :  * All GPUs will reference the data at reduced bandwidth over the PCIe bus. In these
<span class="lineNum">     497 </span>                :            :  * circumstances, use of the environment variable CUDA_VISIBLE_DEVICES is recommended to
<span class="lineNum">     498 </span>                :            :  * restrict CUDA to only use those GPUs that have peer-to-peer support.
<span class="lineNum">     499 </span>                :            :  * Alternatively, users can also set CUDA_MANAGED_FORCE_DEVICE_ALLOC to a non-zero
<span class="lineNum">     500 </span>                :            :  * value to force the driver to always use device memory for physical storage.
<span class="lineNum">     501 </span>                :            :  * When this environment variable is set to a non-zero value, all devices used in
<span class="lineNum">     502 </span>                :            :  * that process that support managed memory have to be peer-to-peer compatible
<span class="lineNum">     503 </span>                :            :  * with each other. The error ::cudaErrorInvalidDevice will be returned if a device
<span class="lineNum">     504 </span>                :            :  * that supports managed memory is used and it is not peer-to-peer compatible with
<span class="lineNum">     505 </span>                :            :  * any of the other managed memory supporting devices that were previously used in
<span class="lineNum">     506 </span>                :            :  * that process, even if ::cudaDeviceReset has been called on those devices. These
<span class="lineNum">     507 </span>                :            :  * environment variables are described in the CUDA programming guide under the
<span class="lineNum">     508 </span>                :            :  * &quot;CUDA environment variables&quot; section.
<span class="lineNum">     509 </span>                :            :  * - On ARM, managed memory is not available on discrete gpu with Drive PX-2.
<span class="lineNum">     510 </span>                :            :  *
<span class="lineNum">     511 </span>                :            :  * \param devPtr - Pointer to allocated device memory
<span class="lineNum">     512 </span>                :            :  * \param size   - Requested allocation size in bytes
<span class="lineNum">     513 </span>                :            :  * \param flags  - Must be either ::cudaMemAttachGlobal or ::cudaMemAttachHost (defaults to ::cudaMemAttachGlobal)
<span class="lineNum">     514 </span>                :            :  *
<span class="lineNum">     515 </span>                :            :  * \return
<span class="lineNum">     516 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     517 </span>                :            :  * ::cudaErrorMemoryAllocation,
<span class="lineNum">     518 </span>                :            :  * ::cudaErrorNotSupported,
<span class="lineNum">     519 </span>                :            :  * ::cudaErrorInvalidValue
<span class="lineNum">     520 </span>                :            :  * \note_init_rt
<span class="lineNum">     521 </span>                :            :  * \note_callback
<span class="lineNum">     522 </span>                :            :  *
<span class="lineNum">     523 </span>                :            :  * \sa ::cudaMallocPitch, ::cudaFree, ::cudaMallocArray, ::cudaFreeArray,
<span class="lineNum">     524 </span>                :            :  * ::cudaMalloc3D, ::cudaMalloc3DArray,
<span class="lineNum">     525 </span>                :            :  * \ref ::cudaMallocHost(void**, size_t) &quot;cudaMallocHost (C API)&quot;,
<span class="lineNum">     526 </span>                :            :  * ::cudaFreeHost, ::cudaHostAlloc, ::cudaDeviceGetAttribute, ::cudaStreamAttachMemAsync
<span class="lineNum">     527 </span>                :            :  */
<span class="lineNum">     528 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     529 </span>                :            : static __inline__ __host__ cudaError_t cudaMallocManaged(
<span class="lineNum">     530 </span>                :            :   T            **devPtr,
<span class="lineNum">     531 </span>                :            :   size_t         size,
<span class="lineNum">     532 </span>                :            :   unsigned int   flags = cudaMemAttachGlobal
<span class="lineNum">     533 </span>                :            : )
<span class="lineNum">     534 </span>                :            : {
<span class="lineNum">     535 </span>                :            :   return ::cudaMallocManaged((void**)(void*)devPtr, size, flags);
<span class="lineNum">     536 </span>                :            : }
<span class="lineNum">     537 </span>                :            : 
<span class="lineNum">     538 </span>                :            : /**
<span class="lineNum">     539 </span>                :            :  * \brief Attach memory to a stream asynchronously
<span class="lineNum">     540 </span>                :            :  *
<span class="lineNum">     541 </span>                :            :  * Enqueues an operation in \p stream to specify stream association of
<span class="lineNum">     542 </span>                :            :  * \p length bytes of memory starting from \p devPtr. This function is a
<span class="lineNum">     543 </span>                :            :  * stream-ordered operation, meaning that it is dependent on, and will
<span class="lineNum">     544 </span>                :            :  * only take effect when, previous work in stream has completed. Any
<span class="lineNum">     545 </span>                :            :  * previous association is automatically replaced.
<span class="lineNum">     546 </span>                :            :  *
<span class="lineNum">     547 </span>                :            :  * \p devPtr must point to an one of the following types of memories:
<span class="lineNum">     548 </span>                :            :  * - managed memory declared using the __managed__ keyword or allocated with
<span class="lineNum">     549 </span>                :            :  *   ::cudaMallocManaged.
<span class="lineNum">     550 </span>                :            :  * - a valid host-accessible region of system-allocated pageable memory. This
<span class="lineNum">     551 </span>                :            :  *   type of memory may only be specified if the device associated with the
<span class="lineNum">     552 </span>                :            :  *   stream reports a non-zero value for the device attribute
<span class="lineNum">     553 </span>                :            :  *   ::cudaDevAttrPageableMemoryAccess.
<span class="lineNum">     554 </span>                :            :  *
<span class="lineNum">     555 </span>                :            :  * For managed allocations, \p length must be either zero or the entire
<span class="lineNum">     556 </span>                :            :  * allocation's size. Both indicate that the entire allocation's stream
<span class="lineNum">     557 </span>                :            :  * association is being changed. Currently, it is not possible to change stream
<span class="lineNum">     558 </span>                :            :  * association for a portion of a managed allocation.
<span class="lineNum">     559 </span>                :            :  *
<span class="lineNum">     560 </span>                :            :  * For pageable allocations, \p length must be non-zero.
<span class="lineNum">     561 </span>                :            :  *
<span class="lineNum">     562 </span>                :            :  * The stream association is specified using \p flags which must be
<span class="lineNum">     563 </span>                :            :  * one of ::cudaMemAttachGlobal, ::cudaMemAttachHost or ::cudaMemAttachSingle.
<span class="lineNum">     564 </span>                :            :  * The default value for \p flags is ::cudaMemAttachSingle
<span class="lineNum">     565 </span>                :            :  * If the ::cudaMemAttachGlobal flag is specified, the memory can be accessed
<span class="lineNum">     566 </span>                :            :  * by any stream on any device.
<span class="lineNum">     567 </span>                :            :  * If the ::cudaMemAttachHost flag is specified, the program makes a guarantee
<span class="lineNum">     568 </span>                :            :  * that it won't access the memory on the device from any stream on a device that
<span class="lineNum">     569 </span>                :            :  * has a zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess.
<span class="lineNum">     570 </span>                :            :  * If the ::cudaMemAttachSingle flag is specified and \p stream is associated with
<span class="lineNum">     571 </span>                :            :  * a device that has a zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess,
<span class="lineNum">     572 </span>                :            :  * the program makes a guarantee that it will only access the memory on the device
<span class="lineNum">     573 </span>                :            :  * from \p stream. It is illegal to attach singly to the NULL stream, because the
<span class="lineNum">     574 </span>                :            :  * NULL stream is a virtual global stream and not a specific stream. An error will
<span class="lineNum">     575 </span>                :            :  * be returned in this case.
<span class="lineNum">     576 </span>                :            :  *
<span class="lineNum">     577 </span>                :            :  * When memory is associated with a single stream, the Unified Memory system will
<span class="lineNum">     578 </span>                :            :  * allow CPU access to this memory region so long as all operations in \p stream
<span class="lineNum">     579 </span>                :            :  * have completed, regardless of whether other streams are active. In effect,
<span class="lineNum">     580 </span>                :            :  * this constrains exclusive ownership of the managed memory region by
<span class="lineNum">     581 </span>                :            :  * an active GPU to per-stream activity instead of whole-GPU activity.
<span class="lineNum">     582 </span>                :            :  *
<span class="lineNum">     583 </span>                :            :  * Accessing memory on the device from streams that are not associated with
<span class="lineNum">     584 </span>                :            :  * it will produce undefined results. No error checking is performed by the
<span class="lineNum">     585 </span>                :            :  * Unified Memory system to ensure that kernels launched into other streams
<span class="lineNum">     586 </span>                :            :  * do not access this region.
<span class="lineNum">     587 </span>                :            :  *
<span class="lineNum">     588 </span>                :            :  * It is a program's responsibility to order calls to ::cudaStreamAttachMemAsync
<span class="lineNum">     589 </span>                :            :  * via events, synchronization or other means to ensure legal access to memory
<span class="lineNum">     590 </span>                :            :  * at all times. Data visibility and coherency will be changed appropriately
<span class="lineNum">     591 </span>                :            :  * for all kernels which follow a stream-association change.
<span class="lineNum">     592 </span>                :            :  *
<span class="lineNum">     593 </span>                :            :  * If \p stream is destroyed while data is associated with it, the association is
<span class="lineNum">     594 </span>                :            :  * removed and the association reverts to the default visibility of the allocation
<span class="lineNum">     595 </span>                :            :  * as specified at ::cudaMallocManaged. For __managed__ variables, the default
<span class="lineNum">     596 </span>                :            :  * association is always ::cudaMemAttachGlobal. Note that destroying a stream is an
<span class="lineNum">     597 </span>                :            :  * asynchronous operation, and as a result, the change to default association won't
<span class="lineNum">     598 </span>                :            :  * happen until all work in the stream has completed.
<span class="lineNum">     599 </span>                :            :  *
<span class="lineNum">     600 </span>                :            :  * \param stream  - Stream in which to enqueue the attach operation
<span class="lineNum">     601 </span>                :            :  * \param devPtr  - Pointer to memory (must be a pointer to managed memory or
<span class="lineNum">     602 </span>                :            :  *                  to a valid host-accessible region of system-allocated
<span class="lineNum">     603 </span>                :            :  *                  memory)
<span class="lineNum">     604 </span>                :            :  * \param length  - Length of memory (defaults to zero)
<span class="lineNum">     605 </span>                :            :  * \param flags   - Must be one of ::cudaMemAttachGlobal, ::cudaMemAttachHost or ::cudaMemAttachSingle (defaults to ::cudaMemAttachSingle)
<span class="lineNum">     606 </span>                :            :  *
<span class="lineNum">     607 </span>                :            :  * \return
<span class="lineNum">     608 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     609 </span>                :            :  * ::cudaErrorNotReady,
<span class="lineNum">     610 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     611 </span>                :            :  * ::cudaErrorInvalidResourceHandle
<span class="lineNum">     612 </span>                :            :  * \notefnerr
<span class="lineNum">     613 </span>                :            :  * \note_init_rt
<span class="lineNum">     614 </span>                :            :  * \note_callback
<span class="lineNum">     615 </span>                :            :  *
<span class="lineNum">     616 </span>                :            :  * \sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamWaitEvent, ::cudaStreamSynchronize, ::cudaStreamAddCallback, ::cudaStreamDestroy, ::cudaMallocManaged
<span class="lineNum">     617 </span>                :            :  */
<span class="lineNum">     618 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     619 </span>                :            : static __inline__ __host__ cudaError_t cudaStreamAttachMemAsync(
<span class="lineNum">     620 </span>                :            :   cudaStream_t   stream,
<span class="lineNum">     621 </span>                :            :   T              *devPtr,
<span class="lineNum">     622 </span>                :            :   size_t         length = 0,
<span class="lineNum">     623 </span>                :            :   unsigned int   flags  = cudaMemAttachSingle
<span class="lineNum">     624 </span>                :            : )
<span class="lineNum">     625 </span>                :            : {
<span class="lineNum">     626 </span>                :            :   return ::cudaStreamAttachMemAsync(stream, (void*)devPtr, length, flags);
<span class="lineNum">     627 </span>                :            : }
<a name="628"><span class="lineNum">     628 </span>                :            : </a>
<span class="lineNum">     629 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     630 </span>                :<span class="lineCov">          1 : static __inline__ __host__ cudaError_t cudaMalloc(</span>
<span class="lineNum">     631 </span>                :            :   T      **devPtr,
<span class="lineNum">     632 </span>                :            :   size_t   size
<span class="lineNum">     633 </span>                :            : )
<span class="lineNum">     634 </span>                :            : {
<span class="lineNum">     635 </span>                :<span class="lineCov">          1 :   return ::cudaMalloc((void**)(void*)devPtr, size);</span>
<span class="lineNum">     636 </span>                :            : }
<span class="lineNum">     637 </span>                :            : 
<span class="lineNum">     638 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     639 </span>                :            : static __inline__ __host__ cudaError_t cudaMallocHost(
<span class="lineNum">     640 </span>                :            :   T            **ptr,
<span class="lineNum">     641 </span>                :            :   size_t         size,
<span class="lineNum">     642 </span>                :            :   unsigned int   flags = 0
<span class="lineNum">     643 </span>                :            : )
<span class="lineNum">     644 </span>                :            : {
<span class="lineNum">     645 </span>                :            :   return cudaMallocHost((void**)(void*)ptr, size, flags);
<span class="lineNum">     646 </span>                :            : }
<span class="lineNum">     647 </span>                :            : 
<span class="lineNum">     648 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     649 </span>                :            : static __inline__ __host__ cudaError_t cudaMallocPitch(
<span class="lineNum">     650 </span>                :            :   T      **devPtr,
<span class="lineNum">     651 </span>                :            :   size_t  *pitch,
<span class="lineNum">     652 </span>                :            :   size_t   width,
<span class="lineNum">     653 </span>                :            :   size_t   height
<span class="lineNum">     654 </span>                :            : )
<span class="lineNum">     655 </span>                :            : {
<span class="lineNum">     656 </span>                :            :   return ::cudaMallocPitch((void**)(void*)devPtr, pitch, width, height);
<span class="lineNum">     657 </span>                :            : }
<span class="lineNum">     658 </span>                :            : 
<span class="lineNum">     659 </span>                :            : #if defined(__CUDACC__)
<span class="lineNum">     660 </span>                :            : 
<span class="lineNum">     661 </span>                :            : /**
<span class="lineNum">     662 </span>                :            :  * \brief \hl Copies data to the given symbol on the device
<span class="lineNum">     663 </span>                :            :  *
<span class="lineNum">     664 </span>                :            :  * Copies \p count bytes from the memory area pointed to by \p src
<span class="lineNum">     665 </span>                :            :  * to the memory area \p offset bytes from the start of symbol
<span class="lineNum">     666 </span>                :            :  * \p symbol. The memory areas may not overlap. \p symbol is a variable that
<span class="lineNum">     667 </span>                :            :  * resides in global or constant memory space. \p kind can be either
<span class="lineNum">     668 </span>                :            :  * ::cudaMemcpyHostToDevice or ::cudaMemcpyDeviceToDevice.
<span class="lineNum">     669 </span>                :            :  *
<span class="lineNum">     670 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     671 </span>                :            :  * \param src    - Source memory address
<span class="lineNum">     672 </span>                :            :  * \param count  - Size in bytes to copy
<span class="lineNum">     673 </span>                :            :  * \param offset - Offset from start of symbol in bytes
<span class="lineNum">     674 </span>                :            :  * \param kind   - Type of transfer
<span class="lineNum">     675 </span>                :            :  *
<span class="lineNum">     676 </span>                :            :  * \return
<span class="lineNum">     677 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     678 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     679 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     680 </span>                :            :  * ::cudaErrorInvalidMemcpyDirection,
<span class="lineNum">     681 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     682 </span>                :            :  * \notefnerr
<span class="lineNum">     683 </span>                :            :  * \note_sync
<span class="lineNum">     684 </span>                :            :  * \note_string_api_deprecation
<span class="lineNum">     685 </span>                :            :  * \note_init_rt
<span class="lineNum">     686 </span>                :            :  * \note_callback
<span class="lineNum">     687 </span>                :            :  *
<span class="lineNum">     688 </span>                :            :  * \sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray,
<span class="lineNum">     689 </span>                :            :  * ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray,
<span class="lineNum">     690 </span>                :            :  * ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray,
<span class="lineNum">     691 </span>                :            :  * ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync, ::cudaMemcpy2DAsync,
<span class="lineNum">     692 </span>                :            :  * ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync,
<span class="lineNum">     693 </span>                :            :  * ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync,
<span class="lineNum">     694 </span>                :            :  * ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync
<span class="lineNum">     695 </span>                :            :  */
<span class="lineNum">     696 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     697 </span>                :            : static __inline__ __host__ cudaError_t cudaMemcpyToSymbol(
<span class="lineNum">     698 </span>                :            :   const T                   &amp;symbol,
<span class="lineNum">     699 </span>                :            :   const void                *src,
<span class="lineNum">     700 </span>                :            :         size_t               count,
<span class="lineNum">     701 </span>                :            :         size_t               offset = 0,
<span class="lineNum">     702 </span>                :            :         enum cudaMemcpyKind  kind   = cudaMemcpyHostToDevice
<span class="lineNum">     703 </span>                :            : )
<span class="lineNum">     704 </span>                :            : {
<span class="lineNum">     705 </span>                :            :   return ::cudaMemcpyToSymbol((const void*)&amp;symbol, src, count, offset, kind);
<span class="lineNum">     706 </span>                :            : }
<span class="lineNum">     707 </span>                :            : 
<span class="lineNum">     708 </span>                :            : /**
<span class="lineNum">     709 </span>                :            :  * \brief \hl Copies data to the given symbol on the device
<span class="lineNum">     710 </span>                :            :  *
<span class="lineNum">     711 </span>                :            :  * Copies \p count bytes from the memory area pointed to by \p src
<span class="lineNum">     712 </span>                :            :  * to the memory area \p offset bytes from the start of symbol
<span class="lineNum">     713 </span>                :            :  * \p symbol. The memory areas may not overlap. \p symbol is a variable that
<span class="lineNum">     714 </span>                :            :  * resides in global or constant memory space. \p kind can be either
<span class="lineNum">     715 </span>                :            :  * ::cudaMemcpyHostToDevice or ::cudaMemcpyDeviceToDevice.
<span class="lineNum">     716 </span>                :            :  *
<span class="lineNum">     717 </span>                :            :  * ::cudaMemcpyToSymbolAsync() is asynchronous with respect to the host, so
<span class="lineNum">     718 </span>                :            :  * the call may return before the copy is complete. The copy can optionally
<span class="lineNum">     719 </span>                :            :  * be associated to a stream by passing a non-zero \p stream argument. If
<span class="lineNum">     720 </span>                :            :  * \p kind is ::cudaMemcpyHostToDevice and \p stream is non-zero, the copy
<span class="lineNum">     721 </span>                :            :  * may overlap with operations in other streams.
<span class="lineNum">     722 </span>                :            :  *
<span class="lineNum">     723 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     724 </span>                :            :  * \param src    - Source memory address
<span class="lineNum">     725 </span>                :            :  * \param count  - Size in bytes to copy
<span class="lineNum">     726 </span>                :            :  * \param offset - Offset from start of symbol in bytes
<span class="lineNum">     727 </span>                :            :  * \param kind   - Type of transfer
<span class="lineNum">     728 </span>                :            :  * \param stream - Stream identifier
<span class="lineNum">     729 </span>                :            :  *
<span class="lineNum">     730 </span>                :            :  * \return
<span class="lineNum">     731 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     732 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     733 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     734 </span>                :            :  * ::cudaErrorInvalidMemcpyDirection,
<span class="lineNum">     735 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     736 </span>                :            :  * \notefnerr
<span class="lineNum">     737 </span>                :            :  * \note_async
<span class="lineNum">     738 </span>                :            :  * \note_string_api_deprecation
<span class="lineNum">     739 </span>                :            :  * \note_init_rt
<span class="lineNum">     740 </span>                :            :  * \note_callback
<span class="lineNum">     741 </span>                :            :  *
<span class="lineNum">     742 </span>                :            :  * \sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray,
<span class="lineNum">     743 </span>                :            :  * ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray,
<span class="lineNum">     744 </span>                :            :  * ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol,
<span class="lineNum">     745 </span>                :            :  * ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync, ::cudaMemcpy2DAsync,
<span class="lineNum">     746 </span>                :            :  * ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync,
<span class="lineNum">     747 </span>                :            :  * ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync,
<span class="lineNum">     748 </span>                :            :  * ::cudaMemcpyFromSymbolAsync
<span class="lineNum">     749 </span>                :            :  */
<span class="lineNum">     750 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     751 </span>                :            : static __inline__ __host__ cudaError_t cudaMemcpyToSymbolAsync(
<span class="lineNum">     752 </span>                :            :   const T                   &amp;symbol,
<span class="lineNum">     753 </span>                :            :   const void                *src,
<span class="lineNum">     754 </span>                :            :         size_t               count,
<span class="lineNum">     755 </span>                :            :         size_t               offset = 0,
<span class="lineNum">     756 </span>                :            :         enum cudaMemcpyKind  kind   = cudaMemcpyHostToDevice,
<span class="lineNum">     757 </span>                :            :         cudaStream_t         stream = 0
<span class="lineNum">     758 </span>                :            : )
<span class="lineNum">     759 </span>                :            : {
<span class="lineNum">     760 </span>                :            :   return ::cudaMemcpyToSymbolAsync((const void*)&amp;symbol, src, count, offset, kind, stream);
<span class="lineNum">     761 </span>                :            : }
<span class="lineNum">     762 </span>                :            : 
<span class="lineNum">     763 </span>                :            : /**
<span class="lineNum">     764 </span>                :            :  * \brief \hl Copies data from the given symbol on the device
<span class="lineNum">     765 </span>                :            :  *
<span class="lineNum">     766 </span>                :            :  * Copies \p count bytes from the memory area \p offset bytes
<span class="lineNum">     767 </span>                :            :  * from the start of symbol \p symbol to the memory area pointed to by \p dst.
<span class="lineNum">     768 </span>                :            :  * The memory areas may not overlap. \p symbol is a variable that
<span class="lineNum">     769 </span>                :            :  * resides in global or constant memory space. \p kind can be either
<span class="lineNum">     770 </span>                :            :  * ::cudaMemcpyDeviceToHost or ::cudaMemcpyDeviceToDevice.
<span class="lineNum">     771 </span>                :            :  *
<span class="lineNum">     772 </span>                :            :  * \param dst    - Destination memory address
<span class="lineNum">     773 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     774 </span>                :            :  * \param count  - Size in bytes to copy
<span class="lineNum">     775 </span>                :            :  * \param offset - Offset from start of symbol in bytes
<span class="lineNum">     776 </span>                :            :  * \param kind   - Type of transfer
<span class="lineNum">     777 </span>                :            :  *
<span class="lineNum">     778 </span>                :            :  * \return
<span class="lineNum">     779 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     780 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     781 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     782 </span>                :            :  * ::cudaErrorInvalidMemcpyDirection,
<span class="lineNum">     783 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     784 </span>                :            :  * \notefnerr
<span class="lineNum">     785 </span>                :            :  * \note_sync
<span class="lineNum">     786 </span>                :            :  * \note_string_api_deprecation
<span class="lineNum">     787 </span>                :            :  * \note_init_rt
<span class="lineNum">     788 </span>                :            :  * \note_callback
<span class="lineNum">     789 </span>                :            :  *
<span class="lineNum">     790 </span>                :            :  * \sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray,
<span class="lineNum">     791 </span>                :            :  * ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray,
<span class="lineNum">     792 </span>                :            :  * ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol,
<span class="lineNum">     793 </span>                :            :  * ::cudaMemcpyAsync, ::cudaMemcpy2DAsync,
<span class="lineNum">     794 </span>                :            :  * ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync,
<span class="lineNum">     795 </span>                :            :  * ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync,
<span class="lineNum">     796 </span>                :            :  * ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync
<span class="lineNum">     797 </span>                :            :  */
<span class="lineNum">     798 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     799 </span>                :            : static __inline__ __host__ cudaError_t cudaMemcpyFromSymbol(
<span class="lineNum">     800 </span>                :            :         void                *dst,
<span class="lineNum">     801 </span>                :            :   const T                   &amp;symbol,
<span class="lineNum">     802 </span>                :            :         size_t               count,
<span class="lineNum">     803 </span>                :            :         size_t               offset = 0,
<span class="lineNum">     804 </span>                :            :         enum cudaMemcpyKind  kind   = cudaMemcpyDeviceToHost
<span class="lineNum">     805 </span>                :            : )
<span class="lineNum">     806 </span>                :            : {
<span class="lineNum">     807 </span>                :            :   return ::cudaMemcpyFromSymbol(dst, (const void*)&amp;symbol, count, offset, kind);
<span class="lineNum">     808 </span>                :            : }
<span class="lineNum">     809 </span>                :            : 
<span class="lineNum">     810 </span>                :            : /**
<span class="lineNum">     811 </span>                :            :  * \brief \hl Copies data from the given symbol on the device
<span class="lineNum">     812 </span>                :            :  *
<span class="lineNum">     813 </span>                :            :  * Copies \p count bytes from the memory area \p offset bytes
<span class="lineNum">     814 </span>                :            :  * from the start of symbol \p symbol to the memory area pointed to by \p dst.
<span class="lineNum">     815 </span>                :            :  * The memory areas may not overlap. \p symbol is a variable that resides in
<span class="lineNum">     816 </span>                :            :  * global or constant memory space. \p kind can be either
<span class="lineNum">     817 </span>                :            :  * ::cudaMemcpyDeviceToHost or ::cudaMemcpyDeviceToDevice.
<span class="lineNum">     818 </span>                :            :  *
<span class="lineNum">     819 </span>                :            :  * ::cudaMemcpyFromSymbolAsync() is asynchronous with respect to the host, so
<span class="lineNum">     820 </span>                :            :  * the call may return before the copy is complete. The copy can optionally be
<span class="lineNum">     821 </span>                :            :  * associated to a stream by passing a non-zero \p stream argument. If \p kind
<span class="lineNum">     822 </span>                :            :  * is ::cudaMemcpyDeviceToHost and \p stream is non-zero, the copy may overlap
<span class="lineNum">     823 </span>                :            :  * with operations in other streams.
<span class="lineNum">     824 </span>                :            :  *
<span class="lineNum">     825 </span>                :            :  * \param dst    - Destination memory address
<span class="lineNum">     826 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     827 </span>                :            :  * \param count  - Size in bytes to copy
<span class="lineNum">     828 </span>                :            :  * \param offset - Offset from start of symbol in bytes
<span class="lineNum">     829 </span>                :            :  * \param kind   - Type of transfer
<span class="lineNum">     830 </span>                :            :  * \param stream - Stream identifier
<span class="lineNum">     831 </span>                :            :  *
<span class="lineNum">     832 </span>                :            :  * \return
<span class="lineNum">     833 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     834 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     835 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     836 </span>                :            :  * ::cudaErrorInvalidMemcpyDirection,
<span class="lineNum">     837 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     838 </span>                :            :  * \notefnerr
<span class="lineNum">     839 </span>                :            :  * \note_async
<span class="lineNum">     840 </span>                :            :  * \note_string_api_deprecation
<span class="lineNum">     841 </span>                :            :  * \note_init_rt
<span class="lineNum">     842 </span>                :            :  * \note_callback
<span class="lineNum">     843 </span>                :            :  *
<span class="lineNum">     844 </span>                :            :  * \sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray,
<span class="lineNum">     845 </span>                :            :  * ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray,
<span class="lineNum">     846 </span>                :            :  * ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol,
<span class="lineNum">     847 </span>                :            :  * ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync, ::cudaMemcpy2DAsync,
<span class="lineNum">     848 </span>                :            :  * ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync,
<span class="lineNum">     849 </span>                :            :  * ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync,
<span class="lineNum">     850 </span>                :            :  * ::cudaMemcpyToSymbolAsync
<span class="lineNum">     851 </span>                :            :  */
<span class="lineNum">     852 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     853 </span>                :            : static __inline__ __host__ cudaError_t cudaMemcpyFromSymbolAsync(
<span class="lineNum">     854 </span>                :            :         void                *dst,
<span class="lineNum">     855 </span>                :            :   const T                   &amp;symbol,
<span class="lineNum">     856 </span>                :            :         size_t               count,
<span class="lineNum">     857 </span>                :            :         size_t               offset = 0,
<span class="lineNum">     858 </span>                :            :         enum cudaMemcpyKind  kind   = cudaMemcpyDeviceToHost,
<span class="lineNum">     859 </span>                :            :         cudaStream_t         stream = 0
<span class="lineNum">     860 </span>                :            : )
<span class="lineNum">     861 </span>                :            : {
<span class="lineNum">     862 </span>                :            :   return ::cudaMemcpyFromSymbolAsync(dst, (const void*)&amp;symbol, count, offset, kind, stream);
<span class="lineNum">     863 </span>                :            : }
<span class="lineNum">     864 </span>                :            : 
<span class="lineNum">     865 </span>                :            : /**
<span class="lineNum">     866 </span>                :            :  * \brief \hl Finds the address associated with a CUDA symbol
<span class="lineNum">     867 </span>                :            :  *
<span class="lineNum">     868 </span>                :            :  * Returns in \p *devPtr the address of symbol \p symbol on the device.
<span class="lineNum">     869 </span>                :            :  * \p symbol can either be a variable that resides in global or constant memory space.
<span class="lineNum">     870 </span>                :            :  * If \p symbol cannot be found, or if \p symbol is not declared
<span class="lineNum">     871 </span>                :            :  * in the global or constant memory space, \p *devPtr is unchanged and the error
<span class="lineNum">     872 </span>                :            :  * ::cudaErrorInvalidSymbol is returned.
<span class="lineNum">     873 </span>                :            :  *
<span class="lineNum">     874 </span>                :            :  * \param devPtr - Return device pointer associated with symbol
<span class="lineNum">     875 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     876 </span>                :            :  *
<span class="lineNum">     877 </span>                :            :  * \return
<span class="lineNum">     878 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     879 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     880 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     881 </span>                :            :  * \notefnerr
<span class="lineNum">     882 </span>                :            :  * \note_init_rt
<span class="lineNum">     883 </span>                :            :  * \note_callback
<span class="lineNum">     884 </span>                :            :  *
<span class="lineNum">     885 </span>                :            :  * \sa \ref ::cudaGetSymbolAddress(void**, const void*) &quot;cudaGetSymbolAddress (C API)&quot;,
<span class="lineNum">     886 </span>                :            :  * \ref ::cudaGetSymbolSize(size_t*, const T&amp;) &quot;cudaGetSymbolSize (C++ API)&quot;
<span class="lineNum">     887 </span>                :            :  */
<span class="lineNum">     888 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     889 </span>                :            : static __inline__ __host__ cudaError_t cudaGetSymbolAddress(
<span class="lineNum">     890 </span>                :            :         void **devPtr,
<span class="lineNum">     891 </span>                :            :   const T     &amp;symbol
<span class="lineNum">     892 </span>                :            : )
<span class="lineNum">     893 </span>                :            : {
<span class="lineNum">     894 </span>                :            :   return ::cudaGetSymbolAddress(devPtr, (const void*)&amp;symbol);
<span class="lineNum">     895 </span>                :            : }
<span class="lineNum">     896 </span>                :            : 
<span class="lineNum">     897 </span>                :            : /**
<span class="lineNum">     898 </span>                :            :  * \brief \hl Finds the size of the object associated with a CUDA symbol
<span class="lineNum">     899 </span>                :            :  *
<span class="lineNum">     900 </span>                :            :  * Returns in \p *size the size of symbol \p symbol. \p symbol must be a
<span class="lineNum">     901 </span>                :            :  * variable that resides in global or constant memory space.
<span class="lineNum">     902 </span>                :            :  * If \p symbol cannot be found, or if \p symbol is not declared
<span class="lineNum">     903 </span>                :            :  * in global or constant memory space, \p *size is unchanged and the error
<span class="lineNum">     904 </span>                :            :  * ::cudaErrorInvalidSymbol is returned.
<span class="lineNum">     905 </span>                :            :  *
<span class="lineNum">     906 </span>                :            :  * \param size   - Size of object associated with symbol
<span class="lineNum">     907 </span>                :            :  * \param symbol - Device symbol reference
<span class="lineNum">     908 </span>                :            :  *
<span class="lineNum">     909 </span>                :            :  * \return
<span class="lineNum">     910 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     911 </span>                :            :  * ::cudaErrorInvalidSymbol,
<span class="lineNum">     912 </span>                :            :  * ::cudaErrorNoKernelImageForDevice
<span class="lineNum">     913 </span>                :            :  * \notefnerr
<span class="lineNum">     914 </span>                :            :  * \note_init_rt
<span class="lineNum">     915 </span>                :            :  * \note_callback
<span class="lineNum">     916 </span>                :            :  *
<span class="lineNum">     917 </span>                :            :  * \sa \ref ::cudaGetSymbolAddress(void**, const T&amp;) &quot;cudaGetSymbolAddress (C++ API)&quot;,
<span class="lineNum">     918 </span>                :            :  * \ref ::cudaGetSymbolSize(size_t*, const void*) &quot;cudaGetSymbolSize (C API)&quot;
<span class="lineNum">     919 </span>                :            :  */
<span class="lineNum">     920 </span>                :            : template&lt;class T&gt;
<span class="lineNum">     921 </span>                :            : static __inline__ __host__ cudaError_t cudaGetSymbolSize(
<span class="lineNum">     922 </span>                :            :         size_t *size,
<span class="lineNum">     923 </span>                :            :   const T      &amp;symbol
<span class="lineNum">     924 </span>                :            : )
<span class="lineNum">     925 </span>                :            : {
<span class="lineNum">     926 </span>                :            :   return ::cudaGetSymbolSize(size, (const void*)&amp;symbol);
<span class="lineNum">     927 </span>                :            : }
<span class="lineNum">     928 </span>                :            : 
<span class="lineNum">     929 </span>                :            : /**
<span class="lineNum">     930 </span>                :            :  * \brief \hl Binds a memory area to a texture
<span class="lineNum">     931 </span>                :            :  *
<span class="lineNum">     932 </span>                :            :  * Binds \p size bytes of the memory area pointed to by \p devPtr to texture
<span class="lineNum">     933 </span>                :            :  * reference \p tex. \p desc describes how the memory is interpreted when
<span class="lineNum">     934 </span>                :            :  * fetching values from the texture. The \p offset parameter is an optional
<span class="lineNum">     935 </span>                :            :  * byte offset as with the low-level
<span class="lineNum">     936 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t) &quot;cudaBindTexture()&quot;
<span class="lineNum">     937 </span>                :            :  * function. Any memory previously bound to \p tex is unbound.
<span class="lineNum">     938 </span>                :            :  *
<span class="lineNum">     939 </span>                :            :  * \param offset - Offset in bytes
<span class="lineNum">     940 </span>                :            :  * \param tex    - Texture to bind
<span class="lineNum">     941 </span>                :            :  * \param devPtr - Memory area on device
<span class="lineNum">     942 </span>                :            :  * \param desc   - Channel format
<span class="lineNum">     943 </span>                :            :  * \param size   - Size of the memory area pointed to by devPtr
<span class="lineNum">     944 </span>                :            :  *
<span class="lineNum">     945 </span>                :            :  * \return
<span class="lineNum">     946 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     947 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     948 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">     949 </span>                :            :  * \notefnerr
<span class="lineNum">     950 </span>                :            :  * \note_init_rt
<span class="lineNum">     951 </span>                :            :  * \note_callback
<span class="lineNum">     952 </span>                :            :  *
<span class="lineNum">     953 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">     954 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">     955 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t) &quot;cudaBindTexture (C API)&quot;,
<span class="lineNum">     956 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">     957 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">     958 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">     959 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">     960 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">     961 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">     962 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">     963 </span>                :            :  */
<span class="lineNum">     964 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">     965 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTexture(
<span class="lineNum">     966 </span>                :            :         size_t                           *offset,
<span class="lineNum">     967 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">     968 </span>                :            :   const void                             *devPtr,
<span class="lineNum">     969 </span>                :            :   const struct cudaChannelFormatDesc     &amp;desc,
<span class="lineNum">     970 </span>                :            :         size_t                            size = UINT_MAX
<span class="lineNum">     971 </span>                :            : )
<span class="lineNum">     972 </span>                :            : {
<span class="lineNum">     973 </span>                :            :   return ::cudaBindTexture(offset, &amp;tex, devPtr, &amp;desc, size);
<span class="lineNum">     974 </span>                :            : }
<span class="lineNum">     975 </span>                :            : 
<span class="lineNum">     976 </span>                :            : /**
<span class="lineNum">     977 </span>                :            :  * \brief \hl Binds a memory area to a texture
<span class="lineNum">     978 </span>                :            :  *
<span class="lineNum">     979 </span>                :            :  * Binds \p size bytes of the memory area pointed to by \p devPtr to texture
<span class="lineNum">     980 </span>                :            :  * reference \p tex. The channel descriptor is inherited from the texture
<span class="lineNum">     981 </span>                :            :  * reference type. The \p offset parameter is an optional byte offset as with
<span class="lineNum">     982 </span>                :            :  * the low-level
<span class="lineNum">     983 </span>                :            :  * ::cudaBindTexture(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t)
<span class="lineNum">     984 </span>                :            :  * function. Any memory previously bound to \p tex is unbound.
<span class="lineNum">     985 </span>                :            :  *
<span class="lineNum">     986 </span>                :            :  * \param offset - Offset in bytes
<span class="lineNum">     987 </span>                :            :  * \param tex    - Texture to bind
<span class="lineNum">     988 </span>                :            :  * \param devPtr - Memory area on device
<span class="lineNum">     989 </span>                :            :  * \param size   - Size of the memory area pointed to by devPtr
<span class="lineNum">     990 </span>                :            :  *
<span class="lineNum">     991 </span>                :            :  * \return
<span class="lineNum">     992 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">     993 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">     994 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">     995 </span>                :            :  * \notefnerr
<span class="lineNum">     996 </span>                :            :  * \note_init_rt
<span class="lineNum">     997 </span>                :            :  * \note_callback
<span class="lineNum">     998 </span>                :            :  *
<span class="lineNum">     999 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1000 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1001 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t) &quot;cudaBindTexture (C API)&quot;,
<span class="lineNum">    1002 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1003 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1004 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1005 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1006 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1007 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1008 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1009 </span>                :            :  */
<span class="lineNum">    1010 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1011 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTexture(
<span class="lineNum">    1012 </span>                :            :         size_t                           *offset,
<span class="lineNum">    1013 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1014 </span>                :            :   const void                             *devPtr,
<span class="lineNum">    1015 </span>                :            :         size_t                            size = UINT_MAX
<span class="lineNum">    1016 </span>                :            : )
<span class="lineNum">    1017 </span>                :            : {
<span class="lineNum">    1018 </span>                :            :   return cudaBindTexture(offset, tex, devPtr, tex.channelDesc, size);
<span class="lineNum">    1019 </span>                :            : }
<span class="lineNum">    1020 </span>                :            : 
<span class="lineNum">    1021 </span>                :            : /**
<span class="lineNum">    1022 </span>                :            :  * \brief \hl Binds a 2D memory area to a texture
<span class="lineNum">    1023 </span>                :            :  *
<span class="lineNum">    1024 </span>                :            :  * Binds the 2D memory area pointed to by \p devPtr to the
<span class="lineNum">    1025 </span>                :            :  * texture reference \p tex. The size of the area is constrained by
<span class="lineNum">    1026 </span>                :            :  * \p width in texel units, \p height in texel units, and \p pitch in byte
<span class="lineNum">    1027 </span>                :            :  * units. \p desc describes how the memory is interpreted when fetching values
<span class="lineNum">    1028 </span>                :            :  * from the texture. Any memory previously bound to \p tex is unbound.
<span class="lineNum">    1029 </span>                :            :  *
<span class="lineNum">    1030 </span>                :            :  * Since the hardware enforces an alignment requirement on texture base
<span class="lineNum">    1031 </span>                :            :  * addresses,
<span class="lineNum">    1032 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D()&quot;
<span class="lineNum">    1033 </span>                :            :  * returns in \p *offset a byte offset that
<span class="lineNum">    1034 </span>                :            :  * must be applied to texture fetches in order to read from the desired memory.
<span class="lineNum">    1035 </span>                :            :  * This offset must be divided by the texel size and passed to kernels that
<span class="lineNum">    1036 </span>                :            :  * read from the texture so they can be applied to the ::tex2D() function.
<span class="lineNum">    1037 </span>                :            :  * If the device memory pointer was returned from ::cudaMalloc(), the offset is
<span class="lineNum">    1038 </span>                :            :  * guaranteed to be 0 and NULL may be passed as the \p offset parameter.
<span class="lineNum">    1039 </span>                :            :  *
<span class="lineNum">    1040 </span>                :            :  * \param offset - Offset in bytes
<span class="lineNum">    1041 </span>                :            :  * \param tex    - Texture reference to bind
<span class="lineNum">    1042 </span>                :            :  * \param devPtr - 2D memory area on device
<span class="lineNum">    1043 </span>                :            :  * \param desc   - Channel format
<span class="lineNum">    1044 </span>                :            :  * \param width  - Width in texel units
<span class="lineNum">    1045 </span>                :            :  * \param height - Height in texel units
<span class="lineNum">    1046 </span>                :            :  * \param pitch  - Pitch in bytes
<span class="lineNum">    1047 </span>                :            :  *
<span class="lineNum">    1048 </span>                :            :  * \return
<span class="lineNum">    1049 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1050 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1051 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1052 </span>                :            :  * \notefnerr
<span class="lineNum">    1053 </span>                :            :  * \note_init_rt
<span class="lineNum">    1054 </span>                :            :  * \note_callback
<span class="lineNum">    1055 </span>                :            :  *
<span class="lineNum">    1056 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1057 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1058 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1059 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1060 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C API)&quot;,
<span class="lineNum">    1061 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1062 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1063 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1064 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1065 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1066 </span>                :            :  */
<span class="lineNum">    1067 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1068 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTexture2D(
<span class="lineNum">    1069 </span>                :            :         size_t                           *offset,
<span class="lineNum">    1070 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1071 </span>                :            :   const void                             *devPtr,
<span class="lineNum">    1072 </span>                :            :   const struct cudaChannelFormatDesc     &amp;desc,
<span class="lineNum">    1073 </span>                :            :   size_t                                  width,
<span class="lineNum">    1074 </span>                :            :   size_t                                  height,
<span class="lineNum">    1075 </span>                :            :   size_t                                  pitch
<span class="lineNum">    1076 </span>                :            : )
<span class="lineNum">    1077 </span>                :            : {
<span class="lineNum">    1078 </span>                :            :   return ::cudaBindTexture2D(offset, &amp;tex, devPtr, &amp;desc, width, height, pitch);
<span class="lineNum">    1079 </span>                :            : }
<span class="lineNum">    1080 </span>                :            : 
<span class="lineNum">    1081 </span>                :            : /**
<span class="lineNum">    1082 </span>                :            :  * \brief \hl Binds a 2D memory area to a texture
<span class="lineNum">    1083 </span>                :            :  *
<span class="lineNum">    1084 </span>                :            :  * Binds the 2D memory area pointed to by \p devPtr to the
<span class="lineNum">    1085 </span>                :            :  * texture reference \p tex. The size of the area is constrained by
<span class="lineNum">    1086 </span>                :            :  * \p width in texel units, \p height in texel units, and \p pitch in byte
<span class="lineNum">    1087 </span>                :            :  * units. The channel descriptor is inherited from the texture reference
<span class="lineNum">    1088 </span>                :            :  * type. Any memory previously bound to \p tex is unbound.
<span class="lineNum">    1089 </span>                :            :  *
<span class="lineNum">    1090 </span>                :            :  * Since the hardware enforces an alignment requirement on texture base
<span class="lineNum">    1091 </span>                :            :  * addresses,
<span class="lineNum">    1092 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D()&quot;
<span class="lineNum">    1093 </span>                :            :  * returns in \p *offset a byte offset that
<span class="lineNum">    1094 </span>                :            :  * must be applied to texture fetches in order to read from the desired memory.
<span class="lineNum">    1095 </span>                :            :  * This offset must be divided by the texel size and passed to kernels that
<span class="lineNum">    1096 </span>                :            :  * read from the texture so they can be applied to the ::tex2D() function.
<span class="lineNum">    1097 </span>                :            :  * If the device memory pointer was returned from ::cudaMalloc(), the offset is
<span class="lineNum">    1098 </span>                :            :  * guaranteed to be 0 and NULL may be passed as the \p offset parameter.
<span class="lineNum">    1099 </span>                :            :  *
<span class="lineNum">    1100 </span>                :            :  * \param offset - Offset in bytes
<span class="lineNum">    1101 </span>                :            :  * \param tex    - Texture reference to bind
<span class="lineNum">    1102 </span>                :            :  * \param devPtr - 2D memory area on device
<span class="lineNum">    1103 </span>                :            :  * \param width  - Width in texel units
<span class="lineNum">    1104 </span>                :            :  * \param height - Height in texel units
<span class="lineNum">    1105 </span>                :            :  * \param pitch  - Pitch in bytes
<span class="lineNum">    1106 </span>                :            :  *
<span class="lineNum">    1107 </span>                :            :  * \return
<span class="lineNum">    1108 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1109 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1110 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1111 </span>                :            :  * \notefnerr
<span class="lineNum">    1112 </span>                :            :  * \note_init_rt
<span class="lineNum">    1113 </span>                :            :  * \note_callback
<span class="lineNum">    1114 </span>                :            :  *
<span class="lineNum">    1115 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1116 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1117 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1118 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1119 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct textureReference*, const void*, const struct cudaChannelFormatDesc*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C API)&quot;,
<span class="lineNum">    1120 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1121 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1122 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1123 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1124 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1125 </span>                :            :  */
<span class="lineNum">    1126 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1127 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTexture2D(
<span class="lineNum">    1128 </span>                :            :         size_t                           *offset,
<span class="lineNum">    1129 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1130 </span>                :            :   const void                             *devPtr,
<span class="lineNum">    1131 </span>                :            :   size_t                                  width,
<span class="lineNum">    1132 </span>                :            :   size_t                                  height,
<span class="lineNum">    1133 </span>                :            :   size_t                                  pitch
<span class="lineNum">    1134 </span>                :            : )
<span class="lineNum">    1135 </span>                :            : {
<span class="lineNum">    1136 </span>                :            :   return ::cudaBindTexture2D(offset, &amp;tex, devPtr, &amp;tex.channelDesc, width, height, pitch);
<span class="lineNum">    1137 </span>                :            : }
<span class="lineNum">    1138 </span>                :            : 
<span class="lineNum">    1139 </span>                :            : /**
<span class="lineNum">    1140 </span>                :            :  * \brief \hl Binds an array to a texture
<span class="lineNum">    1141 </span>                :            :  *
<span class="lineNum">    1142 </span>                :            :  * Binds the CUDA array \p array to the texture reference \p tex.
<span class="lineNum">    1143 </span>                :            :  * \p desc describes how the memory is interpreted when fetching values from
<span class="lineNum">    1144 </span>                :            :  * the texture. Any CUDA array previously bound to \p tex is unbound.
<span class="lineNum">    1145 </span>                :            :  *
<span class="lineNum">    1146 </span>                :            :  * \param tex   - Texture to bind
<span class="lineNum">    1147 </span>                :            :  * \param array - Memory array on device
<span class="lineNum">    1148 </span>                :            :  * \param desc  - Channel format
<span class="lineNum">    1149 </span>                :            :  *
<span class="lineNum">    1150 </span>                :            :  * \return
<span class="lineNum">    1151 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1152 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1153 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1154 </span>                :            :  * \notefnerr
<span class="lineNum">    1155 </span>                :            :  * \note_init_rt
<span class="lineNum">    1156 </span>                :            :  * \note_callback
<span class="lineNum">    1157 </span>                :            :  *
<span class="lineNum">    1158 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1159 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1160 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1161 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1162 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1163 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1164 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct textureReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindTextureToArray (C API)&quot;,
<span class="lineNum">    1165 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1166 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1167 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode &gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1168 </span>                :            :  */
<span class="lineNum">    1169 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1170 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTextureToArray(
<span class="lineNum">    1171 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1172 </span>                :            :   cudaArray_const_t                       array,
<span class="lineNum">    1173 </span>                :            :   const struct cudaChannelFormatDesc     &amp;desc
<span class="lineNum">    1174 </span>                :            : )
<span class="lineNum">    1175 </span>                :            : {
<span class="lineNum">    1176 </span>                :            :   return ::cudaBindTextureToArray(&amp;tex, array, &amp;desc);
<span class="lineNum">    1177 </span>                :            : }
<span class="lineNum">    1178 </span>                :            : 
<span class="lineNum">    1179 </span>                :            : /**
<span class="lineNum">    1180 </span>                :            :  * \brief \hl Binds an array to a texture
<span class="lineNum">    1181 </span>                :            :  *
<span class="lineNum">    1182 </span>                :            :  * Binds the CUDA array \p array to the texture reference \p tex.
<span class="lineNum">    1183 </span>                :            :  * The channel descriptor is inherited from the CUDA array. Any CUDA array
<span class="lineNum">    1184 </span>                :            :  * previously bound to \p tex is unbound.
<span class="lineNum">    1185 </span>                :            :  *
<span class="lineNum">    1186 </span>                :            :  * \param tex   - Texture to bind
<span class="lineNum">    1187 </span>                :            :  * \param array - Memory array on device
<span class="lineNum">    1188 </span>                :            :  *
<span class="lineNum">    1189 </span>                :            :  * \return
<span class="lineNum">    1190 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1191 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1192 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1193 </span>                :            :  * \notefnerr
<span class="lineNum">    1194 </span>                :            :  * \note_init_rt
<span class="lineNum">    1195 </span>                :            :  * \note_callback
<span class="lineNum">    1196 </span>                :            :  *
<span class="lineNum">    1197 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1198 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1199 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1200 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1201 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1202 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1203 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct textureReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindTextureToArray (C API)&quot;,
<span class="lineNum">    1204 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1205 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1206 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode &gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1207 </span>                :            :  */
<span class="lineNum">    1208 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1209 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTextureToArray(
<span class="lineNum">    1210 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1211 </span>                :            :   cudaArray_const_t                       array
<span class="lineNum">    1212 </span>                :            : )
<span class="lineNum">    1213 </span>                :            : {
<span class="lineNum">    1214 </span>                :            :   struct cudaChannelFormatDesc desc;
<span class="lineNum">    1215 </span>                :            :   cudaError_t                  err = ::cudaGetChannelDesc(&amp;desc, array);
<span class="lineNum">    1216 </span>                :            : 
<span class="lineNum">    1217 </span>                :            :   return err == cudaSuccess ? cudaBindTextureToArray(tex, array, desc) : err;
<span class="lineNum">    1218 </span>                :            : }
<span class="lineNum">    1219 </span>                :            : 
<span class="lineNum">    1220 </span>                :            : /**
<span class="lineNum">    1221 </span>                :            :  * \brief \hl Binds a mipmapped array to a texture
<span class="lineNum">    1222 </span>                :            :  *
<span class="lineNum">    1223 </span>                :            :  * Binds the CUDA mipmapped array \p mipmappedArray to the texture reference \p tex.
<span class="lineNum">    1224 </span>                :            :  * \p desc describes how the memory is interpreted when fetching values from
<span class="lineNum">    1225 </span>                :            :  * the texture. Any CUDA mipmapped array previously bound to \p tex is unbound.
<span class="lineNum">    1226 </span>                :            :  *
<span class="lineNum">    1227 </span>                :            :  * \param tex            - Texture to bind
<span class="lineNum">    1228 </span>                :            :  * \param mipmappedArray - Memory mipmapped array on device
<span class="lineNum">    1229 </span>                :            :  * \param desc           - Channel format
<span class="lineNum">    1230 </span>                :            :  *
<span class="lineNum">    1231 </span>                :            :  * \return
<span class="lineNum">    1232 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1233 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1234 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1235 </span>                :            :  * \notefnerr
<span class="lineNum">    1236 </span>                :            :  * \note_init_rt
<span class="lineNum">    1237 </span>                :            :  * \note_callback
<span class="lineNum">    1238 </span>                :            :  *
<span class="lineNum">    1239 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1240 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1241 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1242 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1243 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1244 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1245 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct textureReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindTextureToArray (C API)&quot;,
<span class="lineNum">    1246 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1247 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1248 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode &gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1249 </span>                :            :  */
<span class="lineNum">    1250 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1251 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTextureToMipmappedArray(
<span class="lineNum">    1252 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1253 </span>                :            :   cudaMipmappedArray_const_t              mipmappedArray,
<span class="lineNum">    1254 </span>                :            :   const struct cudaChannelFormatDesc     &amp;desc
<span class="lineNum">    1255 </span>                :            : )
<span class="lineNum">    1256 </span>                :            : {
<span class="lineNum">    1257 </span>                :            :   return ::cudaBindTextureToMipmappedArray(&amp;tex, mipmappedArray, &amp;desc);
<span class="lineNum">    1258 </span>                :            : }
<span class="lineNum">    1259 </span>                :            : 
<span class="lineNum">    1260 </span>                :            : /**
<span class="lineNum">    1261 </span>                :            :  * \brief \hl Binds a mipmapped array to a texture
<span class="lineNum">    1262 </span>                :            :  *
<span class="lineNum">    1263 </span>                :            :  * Binds the CUDA mipmapped array \p mipmappedArray to the texture reference \p tex.
<span class="lineNum">    1264 </span>                :            :  * The channel descriptor is inherited from the CUDA array. Any CUDA mipmapped array
<span class="lineNum">    1265 </span>                :            :  * previously bound to \p tex is unbound.
<span class="lineNum">    1266 </span>                :            :  *
<span class="lineNum">    1267 </span>                :            :  * \param tex            - Texture to bind
<span class="lineNum">    1268 </span>                :            :  * \param mipmappedArray - Memory mipmapped array on device
<span class="lineNum">    1269 </span>                :            :  *
<span class="lineNum">    1270 </span>                :            :  * \return
<span class="lineNum">    1271 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1272 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1273 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1274 </span>                :            :  * \notefnerr
<span class="lineNum">    1275 </span>                :            :  * \note_init_rt
<span class="lineNum">    1276 </span>                :            :  * \note_callback
<span class="lineNum">    1277 </span>                :            :  *
<span class="lineNum">    1278 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1279 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1280 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1281 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1282 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1283 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1284 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct textureReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindTextureToArray (C API)&quot;,
<span class="lineNum">    1285 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1286 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1287 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode &gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1288 </span>                :            :  */
<span class="lineNum">    1289 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1290 </span>                :            : static __inline__ __host__ cudaError_t cudaBindTextureToMipmappedArray(
<span class="lineNum">    1291 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex,
<span class="lineNum">    1292 </span>                :            :   cudaMipmappedArray_const_t              mipmappedArray
<span class="lineNum">    1293 </span>                :            : )
<span class="lineNum">    1294 </span>                :            : {
<span class="lineNum">    1295 </span>                :            :   struct cudaChannelFormatDesc desc;
<span class="lineNum">    1296 </span>                :            :   cudaArray_t                  levelArray;
<span class="lineNum">    1297 </span>                :            :   cudaError_t                  err = ::cudaGetMipmappedArrayLevel(&amp;levelArray, mipmappedArray, 0);
<span class="lineNum">    1298 </span>                :            :   
<span class="lineNum">    1299 </span>                :            :   if (err != cudaSuccess) {
<span class="lineNum">    1300 </span>                :            :       return err;
<span class="lineNum">    1301 </span>                :            :   }
<span class="lineNum">    1302 </span>                :            :   err = ::cudaGetChannelDesc(&amp;desc, levelArray);
<span class="lineNum">    1303 </span>                :            : 
<span class="lineNum">    1304 </span>                :            :   return err == cudaSuccess ? cudaBindTextureToMipmappedArray(tex, mipmappedArray, desc) : err;
<span class="lineNum">    1305 </span>                :            : }
<span class="lineNum">    1306 </span>                :            : 
<span class="lineNum">    1307 </span>                :            : /**
<span class="lineNum">    1308 </span>                :            :  * \brief \hl Unbinds a texture
<span class="lineNum">    1309 </span>                :            :  *
<span class="lineNum">    1310 </span>                :            :  * Unbinds the texture bound to \p tex. If \p texref is not currently bound, no operation is performed.
<span class="lineNum">    1311 </span>                :            :  *
<span class="lineNum">    1312 </span>                :            :  * \param tex - Texture to unbind
<span class="lineNum">    1313 </span>                :            :  *
<span class="lineNum">    1314 </span>                :            :  * \return 
<span class="lineNum">    1315 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1316 </span>                :            :  * ::cudaErrorInvalidTexture
<span class="lineNum">    1317 </span>                :            :  * \notefnerr
<span class="lineNum">    1318 </span>                :            :  * \note_init_rt
<span class="lineNum">    1319 </span>                :            :  * \note_callback
<span class="lineNum">    1320 </span>                :            :  *
<span class="lineNum">    1321 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1322 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1323 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1324 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1325 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1326 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1327 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1328 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1329 </span>                :            :  * \ref ::cudaUnbindTexture(const struct textureReference*) &quot;cudaUnbindTexture (C API)&quot;,
<span class="lineNum">    1330 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct texture&lt;T, dim, readMode &gt;&amp;) &quot;cudaGetTextureAlignmentOffset (C++ API)&quot;
<span class="lineNum">    1331 </span>                :            :  */
<span class="lineNum">    1332 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1333 </span>                :            : static __inline__ __host__ cudaError_t cudaUnbindTexture(
<span class="lineNum">    1334 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex
<span class="lineNum">    1335 </span>                :            : )
<span class="lineNum">    1336 </span>                :            : {
<span class="lineNum">    1337 </span>                :            :   return ::cudaUnbindTexture(&amp;tex);
<span class="lineNum">    1338 </span>                :            : }
<span class="lineNum">    1339 </span>                :            : 
<span class="lineNum">    1340 </span>                :            : /**
<span class="lineNum">    1341 </span>                :            :  * \brief \hl Get the alignment offset of a texture
<span class="lineNum">    1342 </span>                :            :  *
<span class="lineNum">    1343 </span>                :            :  * Returns in \p *offset the offset that was returned when texture reference
<span class="lineNum">    1344 </span>                :            :  * \p tex was bound.
<span class="lineNum">    1345 </span>                :            :  *
<span class="lineNum">    1346 </span>                :            :  * \param offset - Offset of texture reference in bytes
<span class="lineNum">    1347 </span>                :            :  * \param tex    - Texture to get offset of
<span class="lineNum">    1348 </span>                :            :  *
<span class="lineNum">    1349 </span>                :            :  * \return
<span class="lineNum">    1350 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1351 </span>                :            :  * ::cudaErrorInvalidTexture,
<span class="lineNum">    1352 </span>                :            :  * ::cudaErrorInvalidTextureBinding
<span class="lineNum">    1353 </span>                :            :  * \notefnerr
<span class="lineNum">    1354 </span>                :            :  * \note_init_rt
<span class="lineNum">    1355 </span>                :            :  * \note_callback
<span class="lineNum">    1356 </span>                :            :  *
<span class="lineNum">    1357 </span>                :            :  * \sa \ref ::cudaCreateChannelDesc(void) &quot;cudaCreateChannelDesc (C++ API)&quot;,
<span class="lineNum">    1358 </span>                :            :  * ::cudaGetChannelDesc, ::cudaGetTextureReference,
<span class="lineNum">    1359 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t) &quot;cudaBindTexture (C++ API)&quot;,
<span class="lineNum">    1360 </span>                :            :  * \ref ::cudaBindTexture(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t) &quot;cudaBindTexture (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1361 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, const struct cudaChannelFormatDesc&amp;, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API)&quot;,
<span class="lineNum">    1362 </span>                :            :  * \ref ::cudaBindTexture2D(size_t*, const struct texture&lt;T, dim, readMode&gt;&amp;, const void*, size_t, size_t, size_t) &quot;cudaBindTexture2D (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1363 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindTextureToArray (C++ API)&quot;,
<span class="lineNum">    1364 </span>                :            :  * \ref ::cudaBindTextureToArray(const struct texture&lt;T, dim, readMode&gt;&amp;, cudaArray_const_t) &quot;cudaBindTextureToArray (C++ API, inherited channel descriptor)&quot;,
<span class="lineNum">    1365 </span>                :            :  * \ref ::cudaUnbindTexture(const struct texture&lt;T, dim, readMode&gt;&amp;) &quot;cudaUnbindTexture (C++ API)&quot;,
<span class="lineNum">    1366 </span>                :            :  * \ref ::cudaGetTextureAlignmentOffset(size_t*, const struct textureReference*) &quot;cudaGetTextureAlignmentOffset (C API)&quot;
<span class="lineNum">    1367 </span>                :            :  */
<span class="lineNum">    1368 </span>                :            : template&lt;class T, int dim, enum cudaTextureReadMode readMode&gt;
<span class="lineNum">    1369 </span>                :            : static __inline__ __host__ cudaError_t cudaGetTextureAlignmentOffset(
<span class="lineNum">    1370 </span>                :            :         size_t                           *offset,
<span class="lineNum">    1371 </span>                :            :   const struct texture&lt;T, dim, readMode&gt; &amp;tex
<span class="lineNum">    1372 </span>                :            : )
<span class="lineNum">    1373 </span>                :            : {
<span class="lineNum">    1374 </span>                :            :   return ::cudaGetTextureAlignmentOffset(offset, &amp;tex);
<span class="lineNum">    1375 </span>                :            : }
<span class="lineNum">    1376 </span>                :            : 
<span class="lineNum">    1377 </span>                :            : /**
<span class="lineNum">    1378 </span>                :            :  * \brief \hl Sets the preferred cache configuration for a device function
<span class="lineNum">    1379 </span>                :            :  *
<span class="lineNum">    1380 </span>                :            :  * On devices where the L1 cache and shared memory use the same hardware
<span class="lineNum">    1381 </span>                :            :  * resources, this sets through \p cacheConfig the preferred cache configuration
<span class="lineNum">    1382 </span>                :            :  * for the function specified via \p func. This is only a preference. The
<span class="lineNum">    1383 </span>                :            :  * runtime will use the requested configuration if possible, but it is free to
<span class="lineNum">    1384 </span>                :            :  * choose a different configuration if required to execute \p func.
<span class="lineNum">    1385 </span>                :            :  *
<span class="lineNum">    1386 </span>                :            :  * \p func must be a pointer to a function that executes on the device.
<span class="lineNum">    1387 </span>                :            :  * The parameter specified by \p func must be declared as a \p __global__
<span class="lineNum">    1388 </span>                :            :  * function. If the specified function does not exist,
<span class="lineNum">    1389 </span>                :            :  * then ::cudaErrorInvalidDeviceFunction is returned.
<span class="lineNum">    1390 </span>                :            :  *
<span class="lineNum">    1391 </span>                :            :  * This setting does nothing on devices where the size of the L1 cache and
<span class="lineNum">    1392 </span>                :            :  * shared memory are fixed.
<span class="lineNum">    1393 </span>                :            :  *
<span class="lineNum">    1394 </span>                :            :  * Launching a kernel with a different preference than the most recent
<span class="lineNum">    1395 </span>                :            :  * preference setting may insert a device-side synchronization point.
<span class="lineNum">    1396 </span>                :            :  *
<span class="lineNum">    1397 </span>                :            :  * The supported cache configurations are:
<span class="lineNum">    1398 </span>                :            :  * - ::cudaFuncCachePreferNone: no preference for shared memory or L1 (default)
<span class="lineNum">    1399 </span>                :            :  * - ::cudaFuncCachePreferShared: prefer larger shared memory and smaller L1 cache
<span class="lineNum">    1400 </span>                :            :  * - ::cudaFuncCachePreferL1: prefer larger L1 cache and smaller shared memory
<span class="lineNum">    1401 </span>                :            :  *
<span class="lineNum">    1402 </span>                :            :  * \param func        - device function pointer
<span class="lineNum">    1403 </span>                :            :  * \param cacheConfig - Requested cache configuration
<span class="lineNum">    1404 </span>                :            :  *
<span class="lineNum">    1405 </span>                :            :  * \return
<span class="lineNum">    1406 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1407 </span>                :            :  * ::cudaErrorInvalidDeviceFunction
<span class="lineNum">    1408 </span>                :            :  * \notefnerr
<span class="lineNum">    1409 </span>                :            :  * \note_init_rt
<span class="lineNum">    1410 </span>                :            :  * \note_callback
<span class="lineNum">    1411 </span>                :            :  *
<span class="lineNum">    1412 </span>                :            :  * \ref ::cudaLaunchKernel(const T *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C++ API)&quot;,
<span class="lineNum">    1413 </span>                :            :  * \ref ::cudaFuncSetCacheConfig(const void*, enum cudaFuncCache) &quot;cudaFuncSetCacheConfig (C API)&quot;,
<span class="lineNum">    1414 </span>                :            :  * \ref ::cudaFuncGetAttributes(struct cudaFuncAttributes*, T*) &quot;cudaFuncGetAttributes (C++ API)&quot;,
<span class="lineNum">    1415 </span>                :            :  * ::cudaSetDoubleForDevice,
<span class="lineNum">    1416 </span>                :            :  * ::cudaSetDoubleForHost,
<span class="lineNum">    1417 </span>                :            :  * \ref ::cudaSetupArgument(T, size_t) &quot;cudaSetupArgument (C++ API)&quot;,
<span class="lineNum">    1418 </span>                :            :  * ::cudaThreadGetCacheConfig,
<span class="lineNum">    1419 </span>                :            :  * ::cudaThreadSetCacheConfig
<span class="lineNum">    1420 </span>                :            :  */
<span class="lineNum">    1421 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1422 </span>                :            : static __inline__ __host__ cudaError_t cudaFuncSetCacheConfig(
<span class="lineNum">    1423 </span>                :            :   T                  *func,
<span class="lineNum">    1424 </span>                :            :   enum cudaFuncCache  cacheConfig
<span class="lineNum">    1425 </span>                :            : )
<span class="lineNum">    1426 </span>                :            : {
<span class="lineNum">    1427 </span>                :            :   return ::cudaFuncSetCacheConfig((const void*)func, cacheConfig);
<span class="lineNum">    1428 </span>                :            : }
<span class="lineNum">    1429 </span>                :            : 
<span class="lineNum">    1430 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1431 </span>                :            : static __inline__ __host__ cudaError_t cudaFuncSetSharedMemConfig(
<span class="lineNum">    1432 </span>                :            :   T                        *func,
<span class="lineNum">    1433 </span>                :            :   enum cudaSharedMemConfig  config
<span class="lineNum">    1434 </span>                :            : )
<span class="lineNum">    1435 </span>                :            : {
<span class="lineNum">    1436 </span>                :            :   return ::cudaFuncSetSharedMemConfig((const void*)func, config);
<span class="lineNum">    1437 </span>                :            : }
<span class="lineNum">    1438 </span>                :            : 
<span class="lineNum">    1439 </span>                :            : /**
<span class="lineNum">    1440 </span>                :            :  * \brief Returns occupancy for a device function
<span class="lineNum">    1441 </span>                :            :  *
<span class="lineNum">    1442 </span>                :            :  * Returns in \p *numBlocks the maximum number of active blocks per
<span class="lineNum">    1443 </span>                :            :  * streaming multiprocessor for the device function.
<span class="lineNum">    1444 </span>                :            :  *
<span class="lineNum">    1445 </span>                :            :  * \param numBlocks       - Returned occupancy
<span class="lineNum">    1446 </span>                :            :  * \param func            - Kernel function for which occupancy is calulated
<span class="lineNum">    1447 </span>                :            :  * \param blockSize       - Block size the kernel is intended to be launched with
<span class="lineNum">    1448 </span>                :            :  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
<span class="lineNum">    1449 </span>                :            :  *
<span class="lineNum">    1450 </span>                :            :  * \return
<span class="lineNum">    1451 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1452 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1453 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1454 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1455 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1456 </span>                :            :  * \notefnerr
<span class="lineNum">    1457 </span>                :            :  * \note_init_rt
<span class="lineNum">    1458 </span>                :            :  * \note_callback
<span class="lineNum">    1459 </span>                :            :  *
<span class="lineNum">    1460 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
<span class="lineNum">    1461 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1462 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeWithFlags
<span class="lineNum">    1463 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem
<span class="lineNum">    1464 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1465 </span>                :            :  */
<span class="lineNum">    1466 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1467 </span>                :            : static __inline__ __host__ cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessor(
<span class="lineNum">    1468 </span>                :            :     int   *numBlocks,
<span class="lineNum">    1469 </span>                :            :     T      func,
<span class="lineNum">    1470 </span>                :            :     int    blockSize,
<span class="lineNum">    1471 </span>                :            :     size_t dynamicSMemSize)
<span class="lineNum">    1472 </span>                :            : {
<span class="lineNum">    1473 </span>                :            :     return ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(numBlocks, (const void*)func, blockSize, dynamicSMemSize, cudaOccupancyDefault);
<span class="lineNum">    1474 </span>                :            : }
<span class="lineNum">    1475 </span>                :            : 
<span class="lineNum">    1476 </span>                :            : /**
<span class="lineNum">    1477 </span>                :            :  * \brief Returns occupancy for a device function with the specified flags
<span class="lineNum">    1478 </span>                :            :  *
<span class="lineNum">    1479 </span>                :            :  * Returns in \p *numBlocks the maximum number of active blocks per
<span class="lineNum">    1480 </span>                :            :  * streaming multiprocessor for the device function.
<span class="lineNum">    1481 </span>                :            :  *
<span class="lineNum">    1482 </span>                :            :  * The \p flags parameter controls how special cases are handled. Valid flags include:
<span class="lineNum">    1483 </span>                :            :  *
<span class="lineNum">    1484 </span>                :            :  * - ::cudaOccupancyDefault: keeps the default behavior as
<span class="lineNum">    1485 </span>                :            :  *   ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1486 </span>                :            :  *
<span class="lineNum">    1487 </span>                :            :  * - ::cudaOccupancyDisableCachingOverride: suppresses the default behavior
<span class="lineNum">    1488 </span>                :            :  *   on platform where global caching affects occupancy. On such platforms, if caching
<span class="lineNum">    1489 </span>                :            :  *   is enabled, but per-block SM resource usage would result in zero occupancy, the
<span class="lineNum">    1490 </span>                :            :  *   occupancy calculator will calculate the occupancy as if caching is disabled.
<span class="lineNum">    1491 </span>                :            :  *   Setting this flag makes the occupancy calculator to return 0 in such cases.
<span class="lineNum">    1492 </span>                :            :  *   More information can be found about this feature in the &quot;Unified L1/Texture Cache&quot;
<span class="lineNum">    1493 </span>                :            :  *   section of the Maxwell tuning guide.
<span class="lineNum">    1494 </span>                :            :  *
<span class="lineNum">    1495 </span>                :            :  * \param numBlocks       - Returned occupancy
<span class="lineNum">    1496 </span>                :            :  * \param func            - Kernel function for which occupancy is calulated
<span class="lineNum">    1497 </span>                :            :  * \param blockSize       - Block size the kernel is intended to be launched with
<span class="lineNum">    1498 </span>                :            :  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
<span class="lineNum">    1499 </span>                :            :  * \param flags           - Requested behavior for the occupancy calculator
<span class="lineNum">    1500 </span>                :            :  *
<span class="lineNum">    1501 </span>                :            :  * \return
<span class="lineNum">    1502 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1503 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1504 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1505 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1506 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1507 </span>                :            :  * \notefnerr
<span class="lineNum">    1508 </span>                :            :  * \note_init_rt
<span class="lineNum">    1509 </span>                :            :  * \note_callback
<span class="lineNum">    1510 </span>                :            :  *
<span class="lineNum">    1511 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1512 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1513 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeWithFlags
<span class="lineNum">    1514 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem
<span class="lineNum">    1515 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1516 </span>                :            :  */
<span class="lineNum">    1517 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1518 </span>                :            : static __inline__ __host__ cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
<span class="lineNum">    1519 </span>                :            :     int         *numBlocks,
<span class="lineNum">    1520 </span>                :            :     T            func,
<span class="lineNum">    1521 </span>                :            :     int          blockSize,
<span class="lineNum">    1522 </span>                :            :     size_t       dynamicSMemSize,
<span class="lineNum">    1523 </span>                :            :     unsigned int flags)
<span class="lineNum">    1524 </span>                :            : {
<span class="lineNum">    1525 </span>                :            :     return ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(numBlocks, (const void*)func, blockSize, dynamicSMemSize, flags);
<span class="lineNum">    1526 </span>                :            : }
<span class="lineNum">    1527 </span>                :            : 
<span class="lineNum">    1528 </span>                :            : /**
<span class="lineNum">    1529 </span>                :            :  * Helper functor for cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1530 </span>                :            :  */
<span class="lineNum">    1531 </span>                :            : class __cudaOccupancyB2DHelper {
<span class="lineNum">    1532 </span>                :            :   size_t n;
<span class="lineNum">    1533 </span>                :            : public:
<span class="lineNum">    1534 </span>                :            :   inline __host__ CUDART_DEVICE __cudaOccupancyB2DHelper(size_t n_) : n(n_) {}
<span class="lineNum">    1535 </span>                :            :   inline __host__ CUDART_DEVICE size_t operator()(int)
<span class="lineNum">    1536 </span>                :            :   {
<span class="lineNum">    1537 </span>                :            :       return n;
<span class="lineNum">    1538 </span>                :            :   }
<span class="lineNum">    1539 </span>                :            : };
<span class="lineNum">    1540 </span>                :            : 
<span class="lineNum">    1541 </span>                :            : /**
<span class="lineNum">    1542 </span>                :            :  * \brief Returns grid and block size that achieves maximum potential occupancy for a device function
<span class="lineNum">    1543 </span>                :            :  *
<span class="lineNum">    1544 </span>                :            :  * Returns in \p *minGridSize and \p *blocksize a suggested grid /
<span class="lineNum">    1545 </span>                :            :  * block size pair that achieves the best potential occupancy
<span class="lineNum">    1546 </span>                :            :  * (i.e. the maximum number of active warps with the smallest number
<span class="lineNum">    1547 </span>                :            :  * of blocks).
<span class="lineNum">    1548 </span>                :            :  *
<span class="lineNum">    1549 </span>                :            :  * The \p flags parameter controls how special cases are handled. Valid flags include:
<span class="lineNum">    1550 </span>                :            :  *
<span class="lineNum">    1551 </span>                :            :  * - ::cudaOccupancyDefault: keeps the default behavior as
<span class="lineNum">    1552 </span>                :            :  *   ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1553 </span>                :            :  *
<span class="lineNum">    1554 </span>                :            :  * - ::cudaOccupancyDisableCachingOverride: This flag suppresses the default behavior
<span class="lineNum">    1555 </span>                :            :  *   on platform where global caching affects occupancy. On such platforms, if caching
<span class="lineNum">    1556 </span>                :            :  *   is enabled, but per-block SM resource usage would result in zero occupancy, the
<span class="lineNum">    1557 </span>                :            :  *   occupancy calculator will calculate the occupancy as if caching is disabled.
<span class="lineNum">    1558 </span>                :            :  *   Setting this flag makes the occupancy calculator to return 0 in such cases.
<span class="lineNum">    1559 </span>                :            :  *   More information can be found about this feature in the &quot;Unified L1/Texture Cache&quot;
<span class="lineNum">    1560 </span>                :            :  *   section of the Maxwell tuning guide.
<span class="lineNum">    1561 </span>                :            :  *
<span class="lineNum">    1562 </span>                :            :  * \param minGridSize - Returned minimum grid size needed to achieve the best potential occupancy
<span class="lineNum">    1563 </span>                :            :  * \param blockSize   - Returned block size
<span class="lineNum">    1564 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">    1565 </span>                :            :  * \param blockSizeToDynamicSMemSize - A unary function / functor that takes block size, and returns the size, in bytes, of dynamic shared memory needed for a block
<span class="lineNum">    1566 </span>                :            :  * \param blockSizeLimit  - The maximum block size \p func is designed to work with. 0 means no limit.
<span class="lineNum">    1567 </span>                :            :  * \param flags       - Requested behavior for the occupancy calculator
<span class="lineNum">    1568 </span>                :            :  *
<span class="lineNum">    1569 </span>                :            :  * \return
<span class="lineNum">    1570 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1571 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1572 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1573 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1574 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1575 </span>                :            :  * \notefnerr
<span class="lineNum">    1576 </span>                :            :  * \note_init_rt
<span class="lineNum">    1577 </span>                :            :  * \note_callback
<span class="lineNum">    1578 </span>                :            :  *
<span class="lineNum">    1579 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem
<span class="lineNum">    1580 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1581 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
<span class="lineNum">    1582 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1583 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeWithFlags
<span class="lineNum">    1584 </span>                :            :  */
<span class="lineNum">    1585 </span>                :            : 
<span class="lineNum">    1586 </span>                :            : template&lt;typename UnaryFunction, class T&gt;
<span class="lineNum">    1587 </span>                :            : static __inline__ __host__ CUDART_DEVICE cudaError_t cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(
<span class="lineNum">    1588 </span>                :            :     int           *minGridSize,
<span class="lineNum">    1589 </span>                :            :     int           *blockSize,
<span class="lineNum">    1590 </span>                :            :     T              func,
<span class="lineNum">    1591 </span>                :            :     UnaryFunction  blockSizeToDynamicSMemSize,
<span class="lineNum">    1592 </span>                :            :     int            blockSizeLimit = 0,
<span class="lineNum">    1593 </span>                :            :     unsigned int   flags = 0)
<span class="lineNum">    1594 </span>                :            : {
<span class="lineNum">    1595 </span>                :            :     cudaError_t status;
<span class="lineNum">    1596 </span>                :            : 
<span class="lineNum">    1597 </span>                :            :     // Device and function properties
<span class="lineNum">    1598 </span>                :            :     int                       device;
<span class="lineNum">    1599 </span>                :            :     struct cudaFuncAttributes attr;
<span class="lineNum">    1600 </span>                :            : 
<span class="lineNum">    1601 </span>                :            :     // Limits
<span class="lineNum">    1602 </span>                :            :     int maxThreadsPerMultiProcessor;
<span class="lineNum">    1603 </span>                :            :     int warpSize;
<span class="lineNum">    1604 </span>                :            :     int devMaxThreadsPerBlock;
<span class="lineNum">    1605 </span>                :            :     int multiProcessorCount;
<span class="lineNum">    1606 </span>                :            :     int funcMaxThreadsPerBlock;
<span class="lineNum">    1607 </span>                :            :     int occupancyLimit;
<span class="lineNum">    1608 </span>                :            :     int granularity;
<span class="lineNum">    1609 </span>                :            : 
<span class="lineNum">    1610 </span>                :            :     // Recorded maximum
<span class="lineNum">    1611 </span>                :            :     int maxBlockSize = 0;
<span class="lineNum">    1612 </span>                :            :     int numBlocks    = 0;
<span class="lineNum">    1613 </span>                :            :     int maxOccupancy = 0;
<span class="lineNum">    1614 </span>                :            : 
<span class="lineNum">    1615 </span>                :            :     // Temporary
<span class="lineNum">    1616 </span>                :            :     int blockSizeToTryAligned;
<span class="lineNum">    1617 </span>                :            :     int blockSizeToTry;
<span class="lineNum">    1618 </span>                :            :     int blockSizeLimitAligned;
<span class="lineNum">    1619 </span>                :            :     int occupancyInBlocks;
<span class="lineNum">    1620 </span>                :            :     int occupancyInThreads;
<span class="lineNum">    1621 </span>                :            :     size_t dynamicSMemSize;
<span class="lineNum">    1622 </span>                :            : 
<span class="lineNum">    1623 </span>                :            :     ///////////////////////////
<span class="lineNum">    1624 </span>                :            :     // Check user input
<span class="lineNum">    1625 </span>                :            :     ///////////////////////////
<span class="lineNum">    1626 </span>                :            : 
<span class="lineNum">    1627 </span>                :            :     if (!minGridSize || !blockSize || !func) {
<span class="lineNum">    1628 </span>                :            :         return cudaErrorInvalidValue;
<span class="lineNum">    1629 </span>                :            :     }
<span class="lineNum">    1630 </span>                :            : 
<span class="lineNum">    1631 </span>                :            :     //////////////////////////////////////////////
<span class="lineNum">    1632 </span>                :            :     // Obtain device and function properties
<span class="lineNum">    1633 </span>                :            :     //////////////////////////////////////////////
<span class="lineNum">    1634 </span>                :            : 
<span class="lineNum">    1635 </span>                :            :     status = ::cudaGetDevice(&amp;device);
<span class="lineNum">    1636 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1637 </span>                :            :         return status;
<span class="lineNum">    1638 </span>                :            :     }
<span class="lineNum">    1639 </span>                :            : 
<span class="lineNum">    1640 </span>                :            :     status = cudaDeviceGetAttribute(
<span class="lineNum">    1641 </span>                :            :         &amp;maxThreadsPerMultiProcessor,
<span class="lineNum">    1642 </span>                :            :         cudaDevAttrMaxThreadsPerMultiProcessor,
<span class="lineNum">    1643 </span>                :            :         device);
<span class="lineNum">    1644 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1645 </span>                :            :         return status;
<span class="lineNum">    1646 </span>                :            :     }
<span class="lineNum">    1647 </span>                :            : 
<span class="lineNum">    1648 </span>                :            :     status = cudaDeviceGetAttribute(
<span class="lineNum">    1649 </span>                :            :         &amp;warpSize,
<span class="lineNum">    1650 </span>                :            :         cudaDevAttrWarpSize,
<span class="lineNum">    1651 </span>                :            :         device);
<span class="lineNum">    1652 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1653 </span>                :            :         return status;
<span class="lineNum">    1654 </span>                :            :     }
<span class="lineNum">    1655 </span>                :            : 
<span class="lineNum">    1656 </span>                :            :     status = cudaDeviceGetAttribute(
<span class="lineNum">    1657 </span>                :            :         &amp;devMaxThreadsPerBlock,
<span class="lineNum">    1658 </span>                :            :         cudaDevAttrMaxThreadsPerBlock,
<span class="lineNum">    1659 </span>                :            :         device);
<span class="lineNum">    1660 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1661 </span>                :            :         return status;
<span class="lineNum">    1662 </span>                :            :     }
<span class="lineNum">    1663 </span>                :            : 
<span class="lineNum">    1664 </span>                :            :     status = cudaDeviceGetAttribute(
<span class="lineNum">    1665 </span>                :            :         &amp;multiProcessorCount,
<span class="lineNum">    1666 </span>                :            :         cudaDevAttrMultiProcessorCount,
<span class="lineNum">    1667 </span>                :            :         device);
<span class="lineNum">    1668 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1669 </span>                :            :         return status;
<span class="lineNum">    1670 </span>                :            :     }
<span class="lineNum">    1671 </span>                :            : 
<span class="lineNum">    1672 </span>                :            :     status = cudaFuncGetAttributes(&amp;attr, func);
<span class="lineNum">    1673 </span>                :            :     if (status != cudaSuccess) {
<span class="lineNum">    1674 </span>                :            :         return status;
<span class="lineNum">    1675 </span>                :            :     }
<span class="lineNum">    1676 </span>                :            :     
<span class="lineNum">    1677 </span>                :            :     funcMaxThreadsPerBlock = attr.maxThreadsPerBlock;
<span class="lineNum">    1678 </span>                :            : 
<span class="lineNum">    1679 </span>                :            :     /////////////////////////////////////////////////////////////////////////////////
<span class="lineNum">    1680 </span>                :            :     // Try each block size, and pick the block size with maximum occupancy
<span class="lineNum">    1681 </span>                :            :     /////////////////////////////////////////////////////////////////////////////////
<span class="lineNum">    1682 </span>                :            : 
<span class="lineNum">    1683 </span>                :            :     occupancyLimit = maxThreadsPerMultiProcessor;
<span class="lineNum">    1684 </span>                :            :     granularity    = warpSize;
<span class="lineNum">    1685 </span>                :            : 
<span class="lineNum">    1686 </span>                :            :     if (blockSizeLimit == 0) {
<span class="lineNum">    1687 </span>                :            :         blockSizeLimit = devMaxThreadsPerBlock;
<span class="lineNum">    1688 </span>                :            :     }
<span class="lineNum">    1689 </span>                :            : 
<span class="lineNum">    1690 </span>                :            :     if (devMaxThreadsPerBlock &lt; blockSizeLimit) {
<span class="lineNum">    1691 </span>                :            :         blockSizeLimit = devMaxThreadsPerBlock;
<span class="lineNum">    1692 </span>                :            :     }
<span class="lineNum">    1693 </span>                :            : 
<span class="lineNum">    1694 </span>                :            :     if (funcMaxThreadsPerBlock &lt; blockSizeLimit) {
<span class="lineNum">    1695 </span>                :            :         blockSizeLimit = funcMaxThreadsPerBlock;
<span class="lineNum">    1696 </span>                :            :     }
<span class="lineNum">    1697 </span>                :            : 
<span class="lineNum">    1698 </span>                :            :     blockSizeLimitAligned = ((blockSizeLimit + (granularity - 1)) / granularity) * granularity;
<span class="lineNum">    1699 </span>                :            : 
<span class="lineNum">    1700 </span>                :            :     for (blockSizeToTryAligned = blockSizeLimitAligned; blockSizeToTryAligned &gt; 0; blockSizeToTryAligned -= granularity) {
<span class="lineNum">    1701 </span>                :            :         // This is needed for the first iteration, because
<span class="lineNum">    1702 </span>                :            :         // blockSizeLimitAligned could be greater than blockSizeLimit
<span class="lineNum">    1703 </span>                :            :         //
<span class="lineNum">    1704 </span>                :            :         if (blockSizeLimit &lt; blockSizeToTryAligned) {
<span class="lineNum">    1705 </span>                :            :             blockSizeToTry = blockSizeLimit;
<span class="lineNum">    1706 </span>                :            :         } else {
<span class="lineNum">    1707 </span>                :            :             blockSizeToTry = blockSizeToTryAligned;
<span class="lineNum">    1708 </span>                :            :         }
<span class="lineNum">    1709 </span>                :            :         
<span class="lineNum">    1710 </span>                :            :         dynamicSMemSize = blockSizeToDynamicSMemSize(blockSizeToTry);
<span class="lineNum">    1711 </span>                :            : 
<span class="lineNum">    1712 </span>                :            :         status = cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
<span class="lineNum">    1713 </span>                :            :             &amp;occupancyInBlocks,
<span class="lineNum">    1714 </span>                :            :             func,
<span class="lineNum">    1715 </span>                :            :             blockSizeToTry,
<span class="lineNum">    1716 </span>                :            :             dynamicSMemSize,
<span class="lineNum">    1717 </span>                :            :             flags);
<span class="lineNum">    1718 </span>                :            : 
<span class="lineNum">    1719 </span>                :            :         if (status != cudaSuccess) {
<span class="lineNum">    1720 </span>                :            :             return status;
<span class="lineNum">    1721 </span>                :            :         }
<span class="lineNum">    1722 </span>                :            : 
<span class="lineNum">    1723 </span>                :            :         occupancyInThreads = blockSizeToTry * occupancyInBlocks;
<span class="lineNum">    1724 </span>                :            : 
<span class="lineNum">    1725 </span>                :            :         if (occupancyInThreads &gt; maxOccupancy) {
<span class="lineNum">    1726 </span>                :            :             maxBlockSize = blockSizeToTry;
<span class="lineNum">    1727 </span>                :            :             numBlocks    = occupancyInBlocks;
<span class="lineNum">    1728 </span>                :            :             maxOccupancy = occupancyInThreads;
<span class="lineNum">    1729 </span>                :            :         }
<span class="lineNum">    1730 </span>                :            : 
<span class="lineNum">    1731 </span>                :            :         // Early out if we have reached the maximum
<span class="lineNum">    1732 </span>                :            :         //
<span class="lineNum">    1733 </span>                :            :         if (occupancyLimit == maxOccupancy) {
<span class="lineNum">    1734 </span>                :            :             break;
<span class="lineNum">    1735 </span>                :            :         }
<span class="lineNum">    1736 </span>                :            :     }
<span class="lineNum">    1737 </span>                :            : 
<span class="lineNum">    1738 </span>                :            :     ///////////////////////////
<span class="lineNum">    1739 </span>                :            :     // Return best available
<span class="lineNum">    1740 </span>                :            :     ///////////////////////////
<span class="lineNum">    1741 </span>                :            : 
<span class="lineNum">    1742 </span>                :            :     // Suggested min grid size to achieve a full machine launch
<span class="lineNum">    1743 </span>                :            :     //
<span class="lineNum">    1744 </span>                :            :     *minGridSize = numBlocks * multiProcessorCount;
<span class="lineNum">    1745 </span>                :            :     *blockSize = maxBlockSize;
<span class="lineNum">    1746 </span>                :            : 
<span class="lineNum">    1747 </span>                :            :     return status;
<span class="lineNum">    1748 </span>                :            : }
<span class="lineNum">    1749 </span>                :            : 
<span class="lineNum">    1750 </span>                :            : /**
<span class="lineNum">    1751 </span>                :            :  * \brief Returns grid and block size that achieves maximum potential occupancy for a device function
<span class="lineNum">    1752 </span>                :            :  *
<span class="lineNum">    1753 </span>                :            :  * Returns in \p *minGridSize and \p *blocksize a suggested grid /
<span class="lineNum">    1754 </span>                :            :  * block size pair that achieves the best potential occupancy
<span class="lineNum">    1755 </span>                :            :  * (i.e. the maximum number of active warps with the smallest number
<span class="lineNum">    1756 </span>                :            :  * of blocks).
<span class="lineNum">    1757 </span>                :            :  *
<span class="lineNum">    1758 </span>                :            :  * \param minGridSize - Returned minimum grid size needed to achieve the best potential occupancy
<span class="lineNum">    1759 </span>                :            :  * \param blockSize   - Returned block size
<span class="lineNum">    1760 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">    1761 </span>                :            :  * \param blockSizeToDynamicSMemSize - A unary function / functor that takes block size, and returns the size, in bytes, of dynamic shared memory needed for a block
<span class="lineNum">    1762 </span>                :            :  * \param blockSizeLimit  - The maximum block size \p func is designed to work with. 0 means no limit.
<span class="lineNum">    1763 </span>                :            :  *
<span class="lineNum">    1764 </span>                :            :  * \return
<span class="lineNum">    1765 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1766 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1767 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1768 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1769 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1770 </span>                :            :  * \notefnerr
<span class="lineNum">    1771 </span>                :            :  * \note_init_rt
<span class="lineNum">    1772 </span>                :            :  * \note_callback
<span class="lineNum">    1773 </span>                :            :  *
<span class="lineNum">    1774 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1775 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1776 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
<span class="lineNum">    1777 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1778 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeWithFlags
<span class="lineNum">    1779 </span>                :            :  */
<span class="lineNum">    1780 </span>                :            : 
<span class="lineNum">    1781 </span>                :            : template&lt;typename UnaryFunction, class T&gt;
<span class="lineNum">    1782 </span>                :            : static __inline__ __host__ CUDART_DEVICE cudaError_t cudaOccupancyMaxPotentialBlockSizeVariableSMem(
<span class="lineNum">    1783 </span>                :            :     int           *minGridSize,
<span class="lineNum">    1784 </span>                :            :     int           *blockSize,
<span class="lineNum">    1785 </span>                :            :     T              func,
<span class="lineNum">    1786 </span>                :            :     UnaryFunction  blockSizeToDynamicSMemSize,
<span class="lineNum">    1787 </span>                :            :     int            blockSizeLimit = 0)
<span class="lineNum">    1788 </span>                :            : {
<span class="lineNum">    1789 </span>                :            :     return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, blockSizeToDynamicSMemSize, blockSizeLimit, cudaOccupancyDefault);
<span class="lineNum">    1790 </span>                :            : }
<span class="lineNum">    1791 </span>                :            : 
<span class="lineNum">    1792 </span>                :            : /**
<span class="lineNum">    1793 </span>                :            :  * \brief Returns grid and block size that achieves maximum potential occupancy for a device function
<span class="lineNum">    1794 </span>                :            :  *
<span class="lineNum">    1795 </span>                :            :  * Returns in \p *minGridSize and \p *blocksize a suggested grid /
<span class="lineNum">    1796 </span>                :            :  * block size pair that achieves the best potential occupancy
<span class="lineNum">    1797 </span>                :            :  * (i.e. the maximum number of active warps with the smallest number
<span class="lineNum">    1798 </span>                :            :  * of blocks).
<span class="lineNum">    1799 </span>                :            :  *
<span class="lineNum">    1800 </span>                :            :  * Use \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem if the
<span class="lineNum">    1801 </span>                :            :  * amount of per-block dynamic shared memory changes with different
<span class="lineNum">    1802 </span>                :            :  * block sizes.
<span class="lineNum">    1803 </span>                :            :  *
<span class="lineNum">    1804 </span>                :            :  * \param minGridSize - Returned minimum grid size needed to achieve the best potential occupancy
<span class="lineNum">    1805 </span>                :            :  * \param blockSize   - Returned block size
<span class="lineNum">    1806 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">    1807 </span>                :            :  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
<span class="lineNum">    1808 </span>                :            :  * \param blockSizeLimit  - The maximum block size \p func is designed to work with. 0 means no limit.
<span class="lineNum">    1809 </span>                :            :  *
<span class="lineNum">    1810 </span>                :            :  * \return
<span class="lineNum">    1811 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1812 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1813 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1814 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1815 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1816 </span>                :            :  * \notefnerr
<span class="lineNum">    1817 </span>                :            :  * \note_init_rt
<span class="lineNum">    1818 </span>                :            :  * \note_callback
<span class="lineNum">    1819 </span>                :            :  *
<span class="lineNum">    1820 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeWithFlags
<span class="lineNum">    1821 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1822 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
<span class="lineNum">    1823 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem
<span class="lineNum">    1824 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1825 </span>                :            :  */
<span class="lineNum">    1826 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1827 </span>                :            : static __inline__ __host__ CUDART_DEVICE cudaError_t cudaOccupancyMaxPotentialBlockSize(
<span class="lineNum">    1828 </span>                :            :     int    *minGridSize,
<span class="lineNum">    1829 </span>                :            :     int    *blockSize,
<span class="lineNum">    1830 </span>                :            :     T       func,
<span class="lineNum">    1831 </span>                :            :     size_t  dynamicSMemSize = 0,
<span class="lineNum">    1832 </span>                :            :     int     blockSizeLimit = 0)
<span class="lineNum">    1833 </span>                :            : {
<span class="lineNum">    1834 </span>                :            :   return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, __cudaOccupancyB2DHelper(dynamicSMemSize), blockSizeLimit, cudaOccupancyDefault);
<span class="lineNum">    1835 </span>                :            : }
<span class="lineNum">    1836 </span>                :            : 
<span class="lineNum">    1837 </span>                :            : /**
<span class="lineNum">    1838 </span>                :            :  * \brief Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags
<span class="lineNum">    1839 </span>                :            :  *
<span class="lineNum">    1840 </span>                :            :  * Returns in \p *minGridSize and \p *blocksize a suggested grid /
<span class="lineNum">    1841 </span>                :            :  * block size pair that achieves the best potential occupancy
<span class="lineNum">    1842 </span>                :            :  * (i.e. the maximum number of active warps with the smallest number
<span class="lineNum">    1843 </span>                :            :  * of blocks).
<span class="lineNum">    1844 </span>                :            :  *
<span class="lineNum">    1845 </span>                :            :  * The \p flags parameter controls how special cases are handle. Valid flags include:
<span class="lineNum">    1846 </span>                :            :  *
<span class="lineNum">    1847 </span>                :            :  * - ::cudaOccupancyDefault: keeps the default behavior as
<span class="lineNum">    1848 </span>                :            :  *   ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1849 </span>                :            :  *
<span class="lineNum">    1850 </span>                :            :  * - ::cudaOccupancyDisableCachingOverride: This flag suppresses the default behavior
<span class="lineNum">    1851 </span>                :            :  *   on platform where global caching affects occupancy. On such platforms, if caching
<span class="lineNum">    1852 </span>                :            :  *   is enabled, but per-block SM resource usage would result in zero occupancy, the
<span class="lineNum">    1853 </span>                :            :  *   occupancy calculator will calculate the occupancy as if caching is disabled.
<span class="lineNum">    1854 </span>                :            :  *   Setting this flag makes the occupancy calculator to return 0 in such cases.
<span class="lineNum">    1855 </span>                :            :  *   More information can be found about this feature in the &quot;Unified L1/Texture Cache&quot;
<span class="lineNum">    1856 </span>                :            :  *   section of the Maxwell tuning guide.
<span class="lineNum">    1857 </span>                :            :  *
<span class="lineNum">    1858 </span>                :            :  * Use \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem if the
<span class="lineNum">    1859 </span>                :            :  * amount of per-block dynamic shared memory changes with different
<span class="lineNum">    1860 </span>                :            :  * block sizes.
<span class="lineNum">    1861 </span>                :            :  *
<span class="lineNum">    1862 </span>                :            :  * \param minGridSize - Returned minimum grid size needed to achieve the best potential occupancy
<span class="lineNum">    1863 </span>                :            :  * \param blockSize   - Returned block size
<span class="lineNum">    1864 </span>                :            :  * \param func        - Device function symbol
<span class="lineNum">    1865 </span>                :            :  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
<span class="lineNum">    1866 </span>                :            :  * \param blockSizeLimit  - The maximum block size \p func is designed to work with. 0 means no limit.
<span class="lineNum">    1867 </span>                :            :  * \param flags       - Requested behavior for the occupancy calculator
<span class="lineNum">    1868 </span>                :            :  *
<span class="lineNum">    1869 </span>                :            :  * \return
<span class="lineNum">    1870 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1871 </span>                :            :  * ::cudaErrorInvalidDevice,
<span class="lineNum">    1872 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1873 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    1874 </span>                :            :  * ::cudaErrorUnknown,
<span class="lineNum">    1875 </span>                :            :  * \notefnerr
<span class="lineNum">    1876 </span>                :            :  * \note_init_rt
<span class="lineNum">    1877 </span>                :            :  * \note_callback
<span class="lineNum">    1878 </span>                :            :  *
<span class="lineNum">    1879 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSize
<span class="lineNum">    1880 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
<span class="lineNum">    1881 </span>                :            :  * \sa ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
<span class="lineNum">    1882 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMem
<span class="lineNum">    1883 </span>                :            :  * \sa ::cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags
<span class="lineNum">    1884 </span>                :            :  */
<span class="lineNum">    1885 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1886 </span>                :            : static __inline__ __host__ CUDART_DEVICE cudaError_t cudaOccupancyMaxPotentialBlockSizeWithFlags(
<span class="lineNum">    1887 </span>                :            :     int    *minGridSize,
<span class="lineNum">    1888 </span>                :            :     int    *blockSize,
<span class="lineNum">    1889 </span>                :            :     T      func,
<span class="lineNum">    1890 </span>                :            :     size_t dynamicSMemSize = 0,
<span class="lineNum">    1891 </span>                :            :     int    blockSizeLimit = 0,
<span class="lineNum">    1892 </span>                :            :     unsigned int flags = 0)
<span class="lineNum">    1893 </span>                :            : {
<span class="lineNum">    1894 </span>                :            :     return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, __cudaOccupancyB2DHelper(dynamicSMemSize), blockSizeLimit, flags);
<span class="lineNum">    1895 </span>                :            : }
<span class="lineNum">    1896 </span>                :            : 
<span class="lineNum">    1897 </span>                :            : /**
<span class="lineNum">    1898 </span>                :            :  * \brief \hl Launches a device function
<span class="lineNum">    1899 </span>                :            :  *
<span class="lineNum">    1900 </span>                :            :  * \deprecated This function is deprecated as of CUDA 7.0
<span class="lineNum">    1901 </span>                :            :  *
<span class="lineNum">    1902 </span>                :            :  * Launches the function \p func on the device. The parameter \p func must
<span class="lineNum">    1903 </span>                :            :  * be a function that executes on the device. The parameter specified by \p func
<span class="lineNum">    1904 </span>                :            :  * must be declared as a \p __global__ function.
<span class="lineNum">    1905 </span>                :            :  * \ref ::cudaLaunch(T*) &quot;cudaLaunch()&quot; must be preceded by a call to
<span class="lineNum">    1906 </span>                :            :  * ::cudaConfigureCall() since it pops the data that was pushed by
<span class="lineNum">    1907 </span>                :            :  * ::cudaConfigureCall() from the execution stack.
<span class="lineNum">    1908 </span>                :            :  *
<span class="lineNum">    1909 </span>                :            :  * \param func - Device function pointer
<span class="lineNum">    1910 </span>                :            :  * to execute
<span class="lineNum">    1911 </span>                :            :  *
<span class="lineNum">    1912 </span>                :            :  * \return
<span class="lineNum">    1913 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1914 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    1915 </span>                :            :  * ::cudaErrorInvalidConfiguration,
<span class="lineNum">    1916 </span>                :            :  * ::cudaErrorLaunchFailure,
<span class="lineNum">    1917 </span>                :            :  * ::cudaErrorLaunchTimeout,
<span class="lineNum">    1918 </span>                :            :  * ::cudaErrorLaunchOutOfResources,
<span class="lineNum">    1919 </span>                :            :  * ::cudaErrorSharedObjectSymbolNotFound,
<span class="lineNum">    1920 </span>                :            :  * ::cudaErrorSharedObjectInitFailed,
<span class="lineNum">    1921 </span>                :            :  * ::cudaErrorInvalidPtx,
<span class="lineNum">    1922 </span>                :            :  * ::cudaErrorNoKernelImageForDevice,
<span class="lineNum">    1923 </span>                :            :  * ::cudaErrorJitCompilerNotFound
<span class="lineNum">    1924 </span>                :            :  * \notefnerr
<span class="lineNum">    1925 </span>                :            :  * \note_init_rt
<span class="lineNum">    1926 </span>                :            :  * \note_callback
<span class="lineNum">    1927 </span>                :            :  *
<span class="lineNum">    1928 </span>                :            :  * \ref ::cudaLaunchKernel(const T *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C++ API)&quot;,
<span class="lineNum">    1929 </span>                :            :  * \ref ::cudaFuncSetCacheConfig(T*, enum cudaFuncCache) &quot;cudaFuncSetCacheConfig (C++ API)&quot;,
<span class="lineNum">    1930 </span>                :            :  * \ref ::cudaFuncGetAttributes(struct cudaFuncAttributes*, T*) &quot;cudaFuncGetAttributes (C++ API)&quot;,
<span class="lineNum">    1931 </span>                :            :  * \ref ::cudaLaunch(const void*) &quot;cudaLaunch (C API)&quot;,
<span class="lineNum">    1932 </span>                :            :  * ::cudaSetDoubleForDevice,
<span class="lineNum">    1933 </span>                :            :  * ::cudaSetDoubleForHost,
<span class="lineNum">    1934 </span>                :            :  * \ref ::cudaSetupArgument(T, size_t) &quot;cudaSetupArgument (C++ API)&quot;,
<span class="lineNum">    1935 </span>                :            :  * ::cudaThreadGetCacheConfig,
<span class="lineNum">    1936 </span>                :            :  * ::cudaThreadSetCacheConfig
<span class="lineNum">    1937 </span>                :            :  */
<span class="lineNum">    1938 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1939 </span>                :            : static __inline__ __host__ cudaError_t cudaLaunch(
<span class="lineNum">    1940 </span>                :            :   T *func
<span class="lineNum">    1941 </span>                :            : )
<span class="lineNum">    1942 </span>                :            : {
<span class="lineNum">    1943 </span>                :            :   return ::cudaLaunch((const void*)func);
<span class="lineNum">    1944 </span>                :            : }
<span class="lineNum">    1945 </span>                :            : 
<span class="lineNum">    1946 </span>                :            : /**
<span class="lineNum">    1947 </span>                :            :  * \brief \hl Find out attributes for a given function
<span class="lineNum">    1948 </span>                :            :  *
<span class="lineNum">    1949 </span>                :            :  * This function obtains the attributes of a function specified via \p entry.
<span class="lineNum">    1950 </span>                :            :  * The parameter \p entry must be a pointer to a function that executes
<span class="lineNum">    1951 </span>                :            :  * on the device. The parameter specified by \p entry must be declared as a \p __global__
<span class="lineNum">    1952 </span>                :            :  * function. The fetched attributes are placed in \p attr. If the specified
<span class="lineNum">    1953 </span>                :            :  * function does not exist, then ::cudaErrorInvalidDeviceFunction is returned.
<span class="lineNum">    1954 </span>                :            :  *
<span class="lineNum">    1955 </span>                :            :  * Note that some function attributes such as
<span class="lineNum">    1956 </span>                :            :  * \ref ::cudaFuncAttributes::maxThreadsPerBlock &quot;maxThreadsPerBlock&quot;
<span class="lineNum">    1957 </span>                :            :  * may vary based on the device that is currently being used.
<span class="lineNum">    1958 </span>                :            :  *
<span class="lineNum">    1959 </span>                :            :  * \param attr  - Return pointer to function's attributes
<span class="lineNum">    1960 </span>                :            :  * \param entry - Function to get attributes of
<span class="lineNum">    1961 </span>                :            :  *
<span class="lineNum">    1962 </span>                :            :  * \return
<span class="lineNum">    1963 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    1964 </span>                :            :  * ::cudaErrorInvalidDeviceFunction
<span class="lineNum">    1965 </span>                :            :  * \notefnerr
<span class="lineNum">    1966 </span>                :            :  * \note_init_rt
<span class="lineNum">    1967 </span>                :            :  * \note_callback
<span class="lineNum">    1968 </span>                :            :  *
<span class="lineNum">    1969 </span>                :            :  * \ref ::cudaLaunchKernel(const T *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C++ API)&quot;,
<span class="lineNum">    1970 </span>                :            :  * \ref ::cudaFuncSetCacheConfig(T*, enum cudaFuncCache) &quot;cudaFuncSetCacheConfig (C++ API)&quot;,
<span class="lineNum">    1971 </span>                :            :  * \ref ::cudaFuncGetAttributes(struct cudaFuncAttributes*, const void*) &quot;cudaFuncGetAttributes (C API)&quot;,
<span class="lineNum">    1972 </span>                :            :  * ::cudaSetDoubleForDevice,
<span class="lineNum">    1973 </span>                :            :  * ::cudaSetDoubleForHost,
<span class="lineNum">    1974 </span>                :            :  * \ref ::cudaSetupArgument(T, size_t) &quot;cudaSetupArgument (C++ API)&quot;
<span class="lineNum">    1975 </span>                :            :  */
<span class="lineNum">    1976 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    1977 </span>                :            : static __inline__ __host__ cudaError_t cudaFuncGetAttributes(
<span class="lineNum">    1978 </span>                :            :   struct cudaFuncAttributes *attr,
<span class="lineNum">    1979 </span>                :            :   T                         *entry
<span class="lineNum">    1980 </span>                :            : )
<span class="lineNum">    1981 </span>                :            : {
<span class="lineNum">    1982 </span>                :            :   return ::cudaFuncGetAttributes(attr, (const void*)entry);
<span class="lineNum">    1983 </span>                :            : }
<span class="lineNum">    1984 </span>                :            : 
<span class="lineNum">    1985 </span>                :            : /**
<span class="lineNum">    1986 </span>                :            :  * \brief \hl Set attributes for a given function
<span class="lineNum">    1987 </span>                :            :  *
<span class="lineNum">    1988 </span>                :            :  * This function sets the attributes of a function specified via \p entry.
<span class="lineNum">    1989 </span>                :            :  * The parameter \p entry must be a pointer to a function that executes
<span class="lineNum">    1990 </span>                :            :  * on the device. The parameter specified by \p entry must be declared as a \p __global__
<span class="lineNum">    1991 </span>                :            :  * function. The enumeration defined by \p attr is set to the value defined by \p value.
<span class="lineNum">    1992 </span>                :            :  * If the specified function does not exist, then ::cudaErrorInvalidDeviceFunction is returned.
<span class="lineNum">    1993 </span>                :            :  * If the specified attribute cannot be written, or if the value is incorrect, 
<span class="lineNum">    1994 </span>                :            :  * then ::cudaErrorInvalidValue is returned.
<span class="lineNum">    1995 </span>                :            :  *
<span class="lineNum">    1996 </span>                :            :  * Valid values for \p attr are:
<span class="lineNum">    1997 </span>                :            :  * - ::cudaFuncAttributeMaxDynamicSharedMemorySize - Maximum size of dynamic shared memory per block
<span class="lineNum">    1998 </span>                :            :  * - ::cudaFuncAttributePreferredSharedMemoryCarveout - Preferred shared memory-L1 cache split ratio in percent of maximum shared memory.
<span class="lineNum">    1999 </span>                :            :  *
<span class="lineNum">    2000 </span>                :            :  * \param entry - Function to get attributes of
<span class="lineNum">    2001 </span>                :            :  * \param attr  - Attribute to set
<span class="lineNum">    2002 </span>                :            :  * \param value - Value to set
<span class="lineNum">    2003 </span>                :            :  *
<span class="lineNum">    2004 </span>                :            :  * \return
<span class="lineNum">    2005 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    2006 </span>                :            :  * ::cudaErrorInvalidDeviceFunction,
<span class="lineNum">    2007 </span>                :            :  * ::cudaErrorInvalidValue
<span class="lineNum">    2008 </span>                :            :  * \notefnerr
<span class="lineNum">    2009 </span>                :            :  * \note_init_rt
<span class="lineNum">    2010 </span>                :            :  * \note_callback
<span class="lineNum">    2011 </span>                :            :  *
<span class="lineNum">    2012 </span>                :            :  * \ref ::cudaLaunchKernel(const T *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, cudaStream_t stream) &quot;cudaLaunchKernel (C++ API)&quot;,
<span class="lineNum">    2013 </span>                :            :  * \ref ::cudaFuncSetCacheConfig(T*, enum cudaFuncCache) &quot;cudaFuncSetCacheConfig (C++ API)&quot;,
<span class="lineNum">    2014 </span>                :            :  * \ref ::cudaFuncGetAttributes(struct cudaFuncAttributes*, const void*) &quot;cudaFuncGetAttributes (C API)&quot;,
<span class="lineNum">    2015 </span>                :            :  * ::cudaSetDoubleForDevice,
<span class="lineNum">    2016 </span>                :            :  * ::cudaSetDoubleForHost,
<span class="lineNum">    2017 </span>                :            :  * \ref ::cudaSetupArgument(T, size_t) &quot;cudaSetupArgument (C++ API)&quot;
<span class="lineNum">    2018 </span>                :            :  */
<span class="lineNum">    2019 </span>                :            : template&lt;class T&gt;
<span class="lineNum">    2020 </span>                :            : static __inline__ __host__ cudaError_t cudaFuncSetAttribute(
<span class="lineNum">    2021 </span>                :            :   T                         *entry,
<span class="lineNum">    2022 </span>                :            :   enum cudaFuncAttribute    attr,
<span class="lineNum">    2023 </span>                :            :   int                       value
<span class="lineNum">    2024 </span>                :            : )
<span class="lineNum">    2025 </span>                :            : {
<span class="lineNum">    2026 </span>                :            :   return ::cudaFuncSetAttribute((const void*)entry, attr, value);
<span class="lineNum">    2027 </span>                :            : }
<span class="lineNum">    2028 </span>                :            : 
<span class="lineNum">    2029 </span>                :            : /**
<span class="lineNum">    2030 </span>                :            :  * \brief \hl Binds an array to a surface
<span class="lineNum">    2031 </span>                :            :  *
<span class="lineNum">    2032 </span>                :            :  * Binds the CUDA array \p array to the surface reference \p surf.
<span class="lineNum">    2033 </span>                :            :  * \p desc describes how the memory is interpreted when dealing with
<span class="lineNum">    2034 </span>                :            :  * the surface. Any CUDA array previously bound to \p surf is unbound.
<span class="lineNum">    2035 </span>                :            :  *
<span class="lineNum">    2036 </span>                :            :  * \param surf  - Surface to bind
<span class="lineNum">    2037 </span>                :            :  * \param array - Memory array on device
<span class="lineNum">    2038 </span>                :            :  * \param desc  - Channel format
<span class="lineNum">    2039 </span>                :            :  *
<span class="lineNum">    2040 </span>                :            :  * \return
<span class="lineNum">    2041 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    2042 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    2043 </span>                :            :  * ::cudaErrorInvalidSurface
<span class="lineNum">    2044 </span>                :            :  * \notefnerr
<span class="lineNum">    2045 </span>                :            :  * \note_init_rt
<span class="lineNum">    2046 </span>                :            :  * \note_callback
<span class="lineNum">    2047 </span>                :            :  *
<span class="lineNum">    2048 </span>                :            :  * \sa \ref ::cudaBindSurfaceToArray(const struct surfaceReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindSurfaceToArray (C API)&quot;,
<span class="lineNum">    2049 </span>                :            :  * \ref ::cudaBindSurfaceToArray(const struct surface&lt;T, dim&gt;&amp;, cudaArray_const_t) &quot;cudaBindSurfaceToArray (C++ API, inherited channel descriptor)&quot;
<span class="lineNum">    2050 </span>                :            :  */
<span class="lineNum">    2051 </span>                :            : template&lt;class T, int dim&gt;
<span class="lineNum">    2052 </span>                :            : static __inline__ __host__ cudaError_t cudaBindSurfaceToArray(
<span class="lineNum">    2053 </span>                :            :   const struct surface&lt;T, dim&gt;       &amp;surf,
<span class="lineNum">    2054 </span>                :            :   cudaArray_const_t                   array,
<span class="lineNum">    2055 </span>                :            :   const struct cudaChannelFormatDesc &amp;desc
<span class="lineNum">    2056 </span>                :            : )
<span class="lineNum">    2057 </span>                :            : {
<span class="lineNum">    2058 </span>                :            :   return ::cudaBindSurfaceToArray(&amp;surf, array, &amp;desc);
<span class="lineNum">    2059 </span>                :            : }
<span class="lineNum">    2060 </span>                :            : 
<span class="lineNum">    2061 </span>                :            : /**
<span class="lineNum">    2062 </span>                :            :  * \brief \hl Binds an array to a surface
<span class="lineNum">    2063 </span>                :            :  *
<span class="lineNum">    2064 </span>                :            :  * Binds the CUDA array \p array to the surface reference \p surf.
<span class="lineNum">    2065 </span>                :            :  * The channel descriptor is inherited from the CUDA array. Any CUDA array
<span class="lineNum">    2066 </span>                :            :  * previously bound to \p surf is unbound.
<span class="lineNum">    2067 </span>                :            :  *
<span class="lineNum">    2068 </span>                :            :  * \param surf  - Surface to bind
<span class="lineNum">    2069 </span>                :            :  * \param array - Memory array on device
<span class="lineNum">    2070 </span>                :            :  *
<span class="lineNum">    2071 </span>                :            :  * \return
<span class="lineNum">    2072 </span>                :            :  * ::cudaSuccess,
<span class="lineNum">    2073 </span>                :            :  * ::cudaErrorInvalidValue,
<span class="lineNum">    2074 </span>                :            :  * ::cudaErrorInvalidSurface
<span class="lineNum">    2075 </span>                :            :  * \notefnerr
<span class="lineNum">    2076 </span>                :            :  * \note_init_rt
<span class="lineNum">    2077 </span>                :            :  * \note_callback
<span class="lineNum">    2078 </span>                :            :  *
<span class="lineNum">    2079 </span>                :            :  * \sa \ref ::cudaBindSurfaceToArray(const struct surfaceReference*, cudaArray_const_t, const struct cudaChannelFormatDesc*) &quot;cudaBindSurfaceToArray (C API)&quot;,
<span class="lineNum">    2080 </span>                :            :  * \ref ::cudaBindSurfaceToArray(const struct surface&lt;T, dim&gt;&amp;, cudaArray_const_t, const struct cudaChannelFormatDesc&amp;) &quot;cudaBindSurfaceToArray (C++ API)&quot;
<span class="lineNum">    2081 </span>                :            :  */
<span class="lineNum">    2082 </span>                :            : template&lt;class T, int dim&gt;
<span class="lineNum">    2083 </span>                :            : static __inline__ __host__ cudaError_t cudaBindSurfaceToArray(
<span class="lineNum">    2084 </span>                :            :   const struct surface&lt;T, dim&gt; &amp;surf,
<span class="lineNum">    2085 </span>                :            :   cudaArray_const_t             array
<span class="lineNum">    2086 </span>                :            : )
<span class="lineNum">    2087 </span>                :            : {
<span class="lineNum">    2088 </span>                :            :   struct cudaChannelFormatDesc desc;
<span class="lineNum">    2089 </span>                :            :   cudaError_t                  err = ::cudaGetChannelDesc(&amp;desc, array);
<span class="lineNum">    2090 </span>                :            : 
<span class="lineNum">    2091 </span>                :            :   return err == cudaSuccess ? cudaBindSurfaceToArray(surf, array, desc) : err;
<span class="lineNum">    2092 </span>                :            : }
<span class="lineNum">    2093 </span>                :            : 
<span class="lineNum">    2094 </span>                :            : #endif /* __CUDACC__ */
<span class="lineNum">    2095 </span>                :            : 
<span class="lineNum">    2096 </span>                :            : /** @} */ /* END CUDART_HIGHLEVEL */
<span class="lineNum">    2097 </span>                :            : 
<span class="lineNum">    2098 </span>                :            : #endif /* __cplusplus &amp;&amp; !__CUDACC_RTC__ */
<span class="lineNum">    2099 </span>                :            : 
<span class="lineNum">    2100 </span>                :            : #if !defined(__CUDACC_RTC__)
<span class="lineNum">    2101 </span>                :            : #if defined(__GNUC__)
<span class="lineNum">    2102 </span>                :            : #if defined(__clang__) || (!defined(__PGIC__) &amp;&amp; (__GNUC__ &gt; 4 || (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt;= 6)))
<span class="lineNum">    2103 </span>                :            : #pragma GCC diagnostic pop
<span class="lineNum">    2104 </span>                :            : #endif
<span class="lineNum">    2105 </span>                :            : #elif defined(_MSC_VER)
<span class="lineNum">    2106 </span>                :            : #pragma warning(pop)
<span class="lineNum">    2107 </span>                :            : #endif
<span class="lineNum">    2108 </span>                :            : #endif
<span class="lineNum">    2109 </span>                :            : 
<span class="lineNum">    2110 </span>                :            : #if defined(__UNDEF_CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS_CUDA_RUNTIME_H__)
<span class="lineNum">    2111 </span>                :            : #undef __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__
<span class="lineNum">    2112 </span>                :            : #undef __UNDEF_CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS_CUDA_RUNTIME_H__
<span class="lineNum">    2113 </span>                :            : #endif
<span class="lineNum">    2114 </span>                :            : 
<span class="lineNum">    2115 </span>                :            : #endif /* !__CUDA_RUNTIME_H__ */
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
